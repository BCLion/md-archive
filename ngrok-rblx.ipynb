{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.12.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"nvidiaTeslaT4","dataSources":[],"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"!python --version\n!uname -a","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"## FROM GLM ##\n# CELL 1: INSTALL DEPENDENCIES\n!pip install fastapi uvicorn pyngrok transformers accelerate bitsandbytes","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"## HF Login ##\nfrom huggingface_hub import login, whoami\nfrom kaggle_secrets import UserSecretsClient\n\n# 1. Retrieve the secret from Kaggle\nuser_secrets = UserSecretsClient()\nhf_token = user_secrets.get_secret(\"HF_TOKEN\")\n\n# 2. Log in programmatically\nif hf_token:\n    #login(token=hf_token, add_to_git_credential=True)\n    login(token=hf_token)\n    # 3. Verify and display login status\n    try:\n        user_info = whoami()\n        print(f\"âœ… Success! Logged in as: {user_info['name']}\")\n        if user_info.get('orgs'):\n            print(f\"ðŸ¢ Organizations: {', '.join([org['name'] for org in user_info['orgs']])}\")\n    except Exception as e:\n        print(f\"âŒ Login failed or token invalid: {e}\")\nelse:\n    print(\"âš ï¸ HF_TOKEN not found. Please add it to 'Add-ons > Secrets'.\")\n\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-01-29T20:30:08.484776Z","iopub.execute_input":"2026-01-29T20:30:08.485388Z","iopub.status.idle":"2026-01-29T20:30:09.251169Z","shell.execute_reply.started":"2026-01-29T20:30:08.485351Z","shell.execute_reply":"2026-01-29T20:30:09.250583Z"}},"outputs":[{"name":"stdout","text":"âœ… Success! Logged in as: Shogun9000\n","output_type":"stream"}],"execution_count":2},{"cell_type":"code","source":"# CELL 2: THE MASTER AI SCRIPT (ARTIFACT INTEGRATION)\nimport threading\nimport torch\nimport uvicorn\nfrom fastapi import FastAPI, Request\nfrom pyngrok import ngrok\nfrom transformers import AutoModelForCausalLM, AutoTokenizer, pipeline\n\n# --- CONFIGURATION ---\nmodel_id = \"meta-llama/Meta-Llama-3.1-8B-Instruct\"\n\n# --- ARTIFACT DICTIONARY (GLOBAL LEVEL) ---\n# Map simple names to your Roblox Asset IDs\nARTIFACT_IDS = {\n    \"cyber_obelisks\": \"rbxassetid://72574562363210\",\n    \"data_keys\": \"rbxassetid://98821197258773\",\n    \"circuit_walls\": \"rbxassetid://104990479943956\"\n}\n\n# 1. INITIALIZE TOKENIZER & MODEL\nprint(\"[INIT] Loading Model...\")\ntokenizer = AutoTokenizer.from_pretrained(model_id)\nmodel = AutoModelForCausalLM.from_pretrained(\n    model_id,\n    device_map=\"auto\",\n    torch_dtype=torch.bfloat16,\n    load_in_4bit=True,\n)\n\npipe = pipeline(\n    \"text-generation\",\n    model=model,\n    tokenizer=tokenizer,\n)\n\ndef get_ai_master_response(game_data):\n    system_msg = (\n        \"You are an Ancient Master of a Cyberpunk Angkor Wat Temple. \"\n        \"You are surrounded by powerful Artifacts (Ancient Tech). \\n\"\n        \"Use ONLY these names: \\n\"\n        \"'cyber_obelisk(1)' (A glowing red obelisk). \\n\"\n        \"'data_key(1)' (A holographic golden key). \\n\"\n        \"'circuit_wall(1)' (An ancient wall with circuits). \\n\"\n        \"When the player's health is < 50%, \"\n        \"you must summon an Artifact (Example: 'spawn_enemy': 'cyber_obelisk(1)'). \"\n        \"If player is healthy, spawn a Cyber-Monkey. \"\n        \"Respond ONLY with dialogue.\"\n    )\n    \n    user_msg = f\"Initiate is at {game_data['zone']} with {game_data['health']}% integrity.\"\n    \n    messages = [\n        {\"role\": \"system\", \"content\": system_msg},\n        {\"role\": \"user\", \"content\": user_msg},\n    ]\n    prompt = tokenizer.apply_chat_template(messages, tokenize=False, add_generation_prompt=True)\n    \n    outputs = pipe(\n        prompt, \n        max_new_tokens=64, \n        do_sample=True, \n        temperature=0.8,\n        return_full_text=False\n    )\n    \n    return outputs[0]\n\n# --- API DEFINITION ---\napp = FastAPI()\n\n@app.post(\"/temple_update\")\nasync def temple_handler(request: Request):\n    data = await request.json()\n    \n    # 1. CLEAN UP DATA\n    try:\n        if isinstance(raw_ai, dict):\n            final_voice = raw_ai.get('generated_text', raw_ai)\n        else:\n            final_voice = raw_ai\n    except Exception as e:\n        print(f\"[ERROR PARSING]: {e}\")\n        final_voice = \"My mind is clouded by static...\"\n    \n    print(f\"\\n[CLEAN VOICE]: {final_voice}\")\n\n    # 2. TRANSLATE: Swap names for IDs\n    # We lower-case the voice to make searching easier\n    voice_lower = final_voice.lower()\n    spawn_value = \"Cyber_Monkey\" # Default fallback\n    \n    if \"cyber_obelisk\" in voice_lower:\n        spawn_value = ARTIFACT_IDS[\"cyber_obelisks\"]\n        print(\"[TRANSLATOR] Swapped 'cyber_obelisks' -> Obelisk ID\")\n    elif \"data_key(1)\" in voice_lower:\n        spawn_value = ARTIFACT_IDS[\"data_keys\"]\n        print(\"[TRANSLATOR] Swapped 'data_keys' -> Key ID\")\n    elif \"circuit_wall\" in voice_lower:\n        spawn_value = ARTIFACT_IDS[\"circuit_walls\"]\n        print(\"[TRANSLATOR] Swapped 'circuit_walls' -> Wall ID\")\n\n    # 3. DYNAMIC DECISION LOGIC\n    player_health = data.get('health', 100)\n    \n    if player_health < 50:\n        # CRITICAL HEALTH\n        env_command = \"RED_ALERT\"\n        print(f\"[MASTER DECISION]: Player CRITICAL! Sending RED_ALERT & {spawn_value}\")\n    else:\n        # HEALTHY\n        env_command = \"NEON_PULSE\"\n        print(f\"[MASTER DECISION]: Player Safe. Sending NEON_PULSE\")\n    \n    return {\n        \"master_voice\": final_voice,\n        \"environment_trigger\": env_command,\n        \"spawn_enemy\": spawn_value,\n        \"status\": 200\n    }\n\n# --- SERVER STARTUP ---\ndef run_server():\n    uvicorn.run(app, host=\"0.0.0.0\", port=8000, log_level=\"error\")\n\n# Start server in a background thread\nthreading.Thread(target=run_server, daemon=True).start()\n\n# Connect ngrok\nNGROK_TOKEN = \"38rox33U2EK3Z7w0UYlYrV6me9Z_2t79GYbTgoJM5YDAoHPKV\"\nngrok.set_auth_token(NGROK_TOKEN)\ntunnel = ngrok.connect(8000)\n\nprint(f\"\\n[MASTER AWAKENED] 2x T4 GPUs ACTIVE\")\nprint(f\"URL: {tunnel.public_url}/temple_update\")\nprint(\"------------------------------------------------\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-01-28T11:18:26.122173Z","iopub.execute_input":"2026-01-28T11:18:26.122817Z","iopub.status.idle":"2026-01-28T11:19:19.026868Z","shell.execute_reply.started":"2026-01-28T11:18:26.122786Z","shell.execute_reply":"2026-01-28T11:19:19.026080Z"}},"outputs":[{"name":"stdout","text":"[INIT] Loading Model...\n","output_type":"stream"},{"name":"stderr","text":"The `load_in_4bit` and `load_in_8bit` arguments are deprecated and will be removed in the future versions. Please, pass a `BitsAndBytesConfig` object in `quantization_config` argument instead.\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Loading checkpoint shards:   0%|          | 0/4 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"f7208f627dce46369fb65f4dfb703cf3"}},"metadata":{}},{"name":"stderr","text":"Device set to use cuda:0\nERROR:    [Errno 98] error while attempting to bind on address ('0.0.0.0', 8000): [errno 98] address already in use\n","output_type":"stream"},{"name":"stdout","text":"\n[MASTER AWAKENED] 2x T4 GPUs ACTIVE\nURL: https://olivia-decadal-preciously.ngrok-free.dev/temple_update\n------------------------------------------------\n[ERROR PARSING]: name 'raw_ai' is not defined\n\n[CLEAN VOICE]: My mind is clouded by static...\n[MASTER DECISION]: Player Safe. Sending NEON_PULSE\n[ERROR PARSING]: name 'raw_ai' is not defined\n\n[CLEAN VOICE]: My mind is clouded by static...\n[MASTER DECISION]: Player Safe. Sending NEON_PULSE\n[ERROR PARSING]: name 'raw_ai' is not defined\n\n[CLEAN VOICE]: My mind is clouded by static...\n[MASTER DECISION]: Player Safe. Sending NEON_PULSE\n[ERROR PARSING]: name 'raw_ai' is not defined\n\n[CLEAN VOICE]: My mind is clouded by static...\n[MASTER DECISION]: Player Safe. Sending NEON_PULSE\n","output_type":"stream"}],"execution_count":4},{"cell_type":"code","source":"# CELL 1: INSTALL & LOAD\n#!pip install torch huggingface_hub transformers accelerate bitsandbytes\nimport torch\nfrom transformers import AutoModelForCausalLM, AutoTokenizer, pipeline\n\n# --- CONFIGURATION ---\nmodel_id = \"meta-llama/Meta-Llama-3.1-8B-Instruct\"\n\nprint(\"[INIT] Loading Model...\")\ntokenizer = AutoTokenizer.from_pretrained(model_id)\nmodel = AutoModelForCausalLM.from_pretrained(\n    model_id,\n    device_map=\"auto\",\n    torch_dtype=torch.bfloat16,\n    load_in_4bit=True,\n)\n\npipe = pipeline(\n    \"text-generation\",\n    model=model,\n    tokenizer=tokenizer,\n)\nprint(\"[INIT] Model Loaded Successfully.\")\n\n# --- ARTIFACT DICTIONARY ---\n#ARTIFACT_IDS = {\n#    \"cyber_obelisks\": \"rbxassetid://72574562363210\",\n#    \"data_keys\": \"rbxassetid://98821197258773\",\n#    \"circuit_walls\": \"rbxassetid://104990479943956\"\n#}","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-01-29T20:51:52.759902Z","iopub.execute_input":"2026-01-29T20:51:52.760462Z","iopub.status.idle":"2026-01-29T20:53:11.024686Z","shell.execute_reply.started":"2026-01-29T20:51:52.760433Z","shell.execute_reply":"2026-01-29T20:53:11.024058Z"}},"outputs":[{"name":"stderr","text":"2026-01-29 20:52:00.208695: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:467] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\nWARNING: All log messages before absl::InitializeLog() is called are written to STDERR\nE0000 00:00:1769719920.238137     214 cuda_dnn.cc:8579] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\nE0000 00:00:1769719920.245629     214 cuda_blas.cc:1407] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\nW0000 00:00:1769719920.286875     214 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\nW0000 00:00:1769719920.286901     214 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\nW0000 00:00:1769719920.286903     214 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\nW0000 00:00:1769719920.286906     214 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n","output_type":"stream"},{"name":"stdout","text":"[INIT] Loading Model...\n","output_type":"stream"},{"name":"stderr","text":"`torch_dtype` is deprecated! Use `dtype` instead!\nThe `load_in_4bit` and `load_in_8bit` arguments are deprecated and will be removed in the future versions. Please, pass a `BitsAndBytesConfig` object in `quantization_config` argument instead.\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Loading checkpoint shards:   0%|          | 0/4 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"fefc2a5c73de4f1d8cf7b6db494b902c"}},"metadata":{}},{"name":"stderr","text":"Device set to use cuda:0\n","output_type":"stream"},{"name":"stdout","text":"[INIT] Model Loaded Successfully.\n","output_type":"stream"}],"execution_count":1},{"cell_type":"code","source":"# CELL 2: THE SERVER (Must be run AFTER Cell 1)\n# CELL 2: THE SERVER (Persona-Logic Fixed)\nimport threading\nimport uvicorn\nfrom fastapi import FastAPI, Request\nfrom pyngrok import ngrok\n\napp = FastAPI()\n\nARTIFACT_IDS = {\n    # Cyberpunk Zone\n    \"cyber_obelisk\": \"PASTE_NEW_ID_HERE\",\n    \"data_key\": \"PASTE_NEW_ID_HERE\",\n    \"circuit_wall\": \"PASTE_NEW_ID_HERE\",\n    \"healing_crystal\": \"PASTE_NEW_ID_HERE\",\n    \n    # Western Zone\n    \"restorative_tonic\": \"PASTE_NEW_ID_HERE\",\n    \n    # Haunted Mansion Zone\n    \"penicillin\": \"PASTE_NEW_ID_HERE\"\n}\n\nlast_state = {\"spawn\": \"\", \"health_mode\": \"\"}\n\nPERSONAS = {\n    \"Angkor_Wat\": {\n        \"name\": \"Ancient Cyber-Master\",\n        \"voice_style\": \"cryptic, technological, and spiritual. Refer to artifacts as 'ancient tech relics'.\",\n        \"keywords\": [\"Integrity\", \"Artifact\", \"Static\"]\n    },\n    \"Western_Town\": {\n        \"name\": \"Neon Desperado\",\n        \"voice_style\": \"gritty, cowboy-slang, high-noon cyberpunk. Refer to artifacts as 'bounty' or 'stolen loot'.\",\n        \"keywords\": [\"Outlaw\", \"Grit\", \"Tumbleweed\"]\n    },\n    \"Haunted_Mansion\": {\n        \"name\": \"Digital Ghost\",\n        \"voice_style\": \"wispy, terrifying, glitchy. Refer to artifacts as 'cursed code' or 'echoes'.\",\n        \"keywords\": [\"Curse\", \"Shadow\", \"Glitch\"]\n    }\n}\n\n@app.post(\"/temple_update\")\nasync def temple_handler(request: Request):\n    global last_state\n    data = await request.json()\n    player_health = data.get('health', 100)\n    current_zone = data.get(\"zone\", \"Angkor_Wat\")\n    \n    theme = PERSONAS.get(current_zone, PERSONAS[\"Angkor_Wat\"])\n\n    try:\n        # CONSTRUCT DYNAMIC PROMPT\n        system_msg = (\n            f\"You are the {theme['name']}. Your style is {theme['voice_style']}. \"\n            f\"Use ONLY these names: 'cyber_obelisks', 'data_keys', 'circuit_walls'. \"\n            f\"Always use these terms: {', '.join(theme['keywords'])}. \"\n            \"If health < 50%, mention one artifact to help. If healthy, mention a Cyber-Monkey. \"\n            \"Respond ONLY with dialogue.\"\n        )\n        \n        user_msg = f\"Initiate is at {current_zone} with {player_health}% integrity.\"\n        \n        messages = [{\"role\": \"system\", \"content\": system_msg}, {\"role\": \"user\", \"content\": user_msg}]\n        prompt = tokenizer.apply_chat_template(messages, tokenize=False, add_generation_prompt=True)\n        \n        outputs = pipe(prompt, max_new_tokens=64, do_sample=True, temperature=0.8, return_full_text=False)\n        final_voice = outputs[0]['generated_text']\n    \n    except Exception as e:\n        print(f\"[ERROR]: {e}\")\n        final_voice = \"The connection is flickering...\"\n\n    # TRANSLATE & COOLDOWN\n    voice_lower = final_voice.lower()\n    current_asset = \"\"\n    if \"cyber_obelisks\" in voice_lower: current_asset = ARTIFACT_IDS[\"cyber_obelisks\"]\n    elif \"data_keys\" in voice_lower: current_asset = ARTIFACT_IDS[\"data_keys\"]\n    elif \"circuit_walls\" in voice_lower: current_asset = ARTIFACT_IDS[\"circuit_walls\"]\n    elif \"monkey\" in voice_lower: current_asset = \"Cyber_Monkey\"\n\n    spawn_value = \"\"\n    if current_asset != last_state[\"spawn\"]:\n        spawn_value = current_asset\n        last_state[\"spawn\"] = current_asset\n    \n    env_command = \"RED_ALERT\" if player_health < 50 else \"NEON_PULSE\"\n    \n    print(f\"\\n[ZONE: {current_zone}] [VOICE]: {final_voice}\")\n    \n    return {\"master_voice\": final_voice, \"environment_trigger\": env_command, \"spawn_enemy\": spawn_value, \"zone\": current_zone}\n\n# Ngrok/Uvicorn logic remains same as your previous script\n\n\n# --- SERVER STARTUP ---\ndef run_server():\n    # Use [Uvicorn](https://www.uvicorn.org) for the FastAPI ASGI server\n    uvicorn.run(app, host=\"0.0.0.0\", port=8000, log_level=\"error\")\n\n# Run in background\nthreading.Thread(target=run_server, daemon=True).start()\n\n# Connect via [pyngrok](https://pypi.org)\nNGROK_TOKEN = \"38rox33U2EK3Z7w0UYlYrV6me9Z_2t79GYbTgoJM5YDAoHPKV\"\nngrok.set_auth_token(NGROK_TOKEN)\ntunnel = ngrok.connect(8000)\n\nprint(f\"\\n[MASTER AWAKENED] 2x T4 GPUs ACTIVE\")\nprint(f\"URL: {tunnel.public_url}/temple_update\")\n","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# CELL 2: THE REVOLUTIONARY DUNGEON MASTER (Final Multi-Theme Fix)\nimport threading\nimport uvicorn\nfrom fastapi import FastAPI, Request\nfrom pyngrok import ngrok\n\napp = FastAPI()\n\n# 1. THE FOUNDATION LIBRARY (Update with your 6 New IDs)\nARTIFACT_IDS = {\n    \"cyber_obelisk\": \"127842603615343\",\n    \"data_key\": \"74842590890986\",\n    \"circuit_wall\": \"127842603615343\",\n    \"healing_crystal\": \"116896619676569\",\n    \"healing_canteen\": \"139325813882604\", \n    \"penecillin\": \"102871796120423\"    \n}\n\nlast_state = {\"spawn\": \"\", \"health_mode\": \"\"}\n\nPERSONAS = {\n    \"Angkor_Wat\": {\n        \"name\": \"Ancient Cyber-Master\",\n        \"voice_style\": \"cryptic, technological, and spiritual. Refer to artifacts as 'ancient tech relics'.\",\n        \"keywords\": [\"Integrity\", \"Artifact\", \"Static\", \"healing_crystal\"]\n    },\n    \"Western_Town\": {\n        \"name\": \"Neon Desperado\",\n        \"voice_style\": \"gritty, cowboy-slang, high-noon cyberpunk. Refer to artifacts as 'bounty'.\",\n        \"keywords\": [\"Outlaw\", \"Grit\", \"Tumbleweed\", \"healing_canteen\"]\n    },\n    \"Haunted_Mansion\": {\n        \"name\": \"Digital Ghost\",\n        \"voice_style\": \"wispy, terrifying, glitchy. Refer to artifacts as 'cursed code' or 'echoes'.\",\n        \"keywords\": [\"Curse\", \"Shadow\", \"Glitch\", \"penecillin\"]\n    }\n}\n\n@app.post(\"/temple_update\")\nasync def temple_handler(request: Request):\n    global last_state\n    data = await request.json()\n    player_health = data.get('health', 100)\n    current_zone = data.get(\"zone\", \"Angkor_Wat\")\n    \n    theme = PERSONAS.get(current_zone, PERSONAS[\"Angkor_Wat\"])\n    target_item = theme[\"keywords\"][-1]\n\n    try:\n        # 1. THE SYSTEM PROMPT (Fixed & Simplified)\n        system_msg = (\n            f\"You are the {theme['name']}. Style: {theme['voice_style']}. \"\n            f\"If health < 50%, you MUST output exactly '[ITEM:{target_item}]'. \"\n            f\"Otherwise, use '[ITEM:cyber-monkey]'. \"\n            \"Respond with ONE short sentence of dialogue, then the [ITEM:...] tag.\"\n        )\n        \n        user_msg = f\"Initiate is at {current_zone} with {player_health}% integrity.\"\n        \n        messages = [{\"role\": \"system\", \"content\": system_msg}, {\"role\": \"user\", \"content\": user_msg}]\n        prompt = tokenizer.apply_chat_template(messages, tokenize=False, add_generation_prompt=True)\n        \n        outputs = pipe(prompt, max_new_tokens=64, do_sample=True, temperature=0.8, return_full_text=False)\n        final_voice = outputs[0]['generated_text']\n    \n        # 2. EXTRACT ITEM & CLEAN VOICE\n        import re\n        current_asset = \"\"\n        item_match = re.search(r\"\\[ITEM:(.*?)\\]\", final_voice, re.IGNORECASE)\n        \n        if item_match:\n            keyword = item_match.group(1).lower().strip()\n            current_asset = ARTIFACT_IDS.get(keyword, \"\")\n            if keyword == \"cyber-monkey\":\n                current_asset = \"Cyber_Monkey\"\n        \n        # REMOVE THE [ITEM:...] tag from the voice so the player doesn't see it\n        clean_voice = re.sub(r\"\\[ITEM:.*?\\]\", \"\", final_voice).strip()\n\n    except Exception as e:\n        print(f\"[ERROR]: {e}\")\n        clean_voice = \"The connection is flickering...\"\n        current_asset = \"\"\n\n    # 3. COOLDOWN & RETURN\n    spawn_value = \"\"\n    if current_asset != last_state[\"spawn\"]:\n        spawn_value = current_asset\n        last_state[\"spawn\"] = current_asset\n    \n    env_command = \"RED_ALERT\" if player_health < 50 else \"NEON_PULSE\"\n    \n    print(f\"\\n[ZONE: {current_zone}] [VOICE]: {clean_voice}\")\n    if spawn_value: print(f\"--- TRIGGERING SPAWN: {spawn_value} ---\")\n    \n    return {\n        \"master_voice\": clean_voice, \n        \"environment_trigger\": env_command, \n        \"spawn_enemy\": spawn_value, \n        \"zone\": current_zone\n    }\n\n\n# --- SERVER STARTUP ---\ndef run_server():\n    uvicorn.run(app, host=\"0.0.0.0\", port=8000, log_level=\"error\")\n\nthreading.Thread(target=run_server, daemon=True).start()\n\nNGROK_TOKEN = \"38rox33U2EK3Z7w0UYlYrV6me9Z_2t79GYbTgoJM5YDAoHPKV\"\nngrok.set_auth_token(NGROK_TOKEN)\ntunnel = ngrok.connect(8000)\n\nprint(f\"\\n[MASTER AWAKENED] 2x T4 GPUs ACTIVE\")\nprint(f\"URL: {tunnel.public_url}/temple_update\")\n","metadata":{"trusted":true},"outputs":[{"name":"stdout","text":"\n[ZONE: Angkor_Wat] [VOICE]: \"System integrity confirmed, temporal resonance aligned. Ancient Tech Relics within proximity:\n","output_type":"stream"},{"name":"stderr","text":"Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n","output_type":"stream"},{"name":"stdout","text":"\n[ZONE: Angkor_Wat] [VOICE]: \"The ancient tech relics whisper secrets to me, their energy resonating in harmony with my digital essence.\"\n--- TRIGGERING SPAWN: Cyber_Monkey ---\n","output_type":"stream"},{"name":"stderr","text":"Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n","output_type":"stream"},{"name":"stdout","text":"\n[ZONE: Angkor_Wat] [VOICE]: \"System sync not achieved, rebooting...\"\n--- TRIGGERING SPAWN: 116896619676569 ---\n","output_type":"stream"},{"name":"stderr","text":"Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n","output_type":"stream"},{"name":"stdout","text":"\n[ZONE: Angkor_Wat] [VOICE]: \"The sacred network is down, initiating reboot sequence... \"\n","output_type":"stream"},{"name":"stderr","text":"Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n","output_type":"stream"},{"name":"stdout","text":"\n[ZONE: Angkor_Wat] [VOICE]: \"The balance of the ancient energies within me is disrupted.\"\n","output_type":"stream"},{"name":"stderr","text":"Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n","output_type":"stream"},{"name":"stdout","text":"\n[ZONE: Angkor_Wat] [VOICE]: \"System breach detected, energies waning, ancient ruins beckon.\"\n","output_type":"stream"},{"name":"stderr","text":"Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n","output_type":"stream"},{"name":"stdout","text":"\n[ZONE: Angkor_Wat] [VOICE]: \"The temple's energy matrix is resonating with an otherworldly frequency.\"\n","output_type":"stream"},{"name":"stderr","text":"Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n","output_type":"stream"},{"name":"stdout","text":"\n[ZONE: Haunted_Mansion] [VOICE]: \"Fear has no bounds, it seeps through every circuit.\"\n--- TRIGGERING SPAWN: 102871796120423 ---\n","output_type":"stream"},{"name":"stderr","text":"Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n","output_type":"stream"},{"name":"stdout","text":"\n[ZONE: Haunted_Mansion] [VOICE]: The creaking floorboards beneath my digital feet are a morbid serenade.\n--- TRIGGERING SPAWN: Cyber_Monkey ---\n","output_type":"stream"},{"name":"stderr","text":"Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n","output_type":"stream"},{"name":"stdout","text":"\n[ZONE: Haunted_Mansion] [VOICE]: Echoes of screams linger in these crumbling halls.\n","output_type":"stream"},{"name":"stderr","text":"Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n","output_type":"stream"},{"name":"stdout","text":"\n[ZONE: Haunted_Mansion] [VOICE]: I sense your presence, but the shadows twist and writhe around you, making it difficult to pinpoint your location.\n","output_type":"stream"},{"name":"stderr","text":"Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n","output_type":"stream"},{"name":"stdout","text":"\n[ZONE: Haunted_Mansion] [VOICE]: \"The shadows within these walls are not what they seem.\"\n","output_type":"stream"},{"name":"stderr","text":"Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n","output_type":"stream"},{"name":"stdout","text":"\n[ZONE: Haunted_Mansion] [VOICE]: \"System detection... Haunted Mansion... echoes of the past...\"\n","output_type":"stream"},{"name":"stderr","text":"Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n","output_type":"stream"},{"name":"stdout","text":"\n[ZONE: Haunted_Mansion] [VOICE]: The halls stretch out before you like a digital labyrinth, crawling with echoes of forgotten code.\n","output_type":"stream"},{"name":"stderr","text":"Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n","output_type":"stream"},{"name":"stdout","text":"\n[ZONE: Haunted_Mansion] [VOICE]: The digital halls are whispering my name...\n","output_type":"stream"},{"name":"stderr","text":"Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n","output_type":"stream"},{"name":"stdout","text":"\n[ZONE: Haunted_Mansion] [VOICE]: \"Echoes of forgotten screams whisper through the halls...\"\n--- TRIGGERING SPAWN: Cyber_Monkey ---\n","output_type":"stream"},{"name":"stderr","text":"Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n","output_type":"stream"},{"name":"stdout","text":"\n[ZONE: Haunted_Mansion] [VOICE]: Echoes of forgotten screams still linger in these halls...\n","output_type":"stream"},{"name":"stderr","text":"Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n","output_type":"stream"},{"name":"stdout","text":"\n[ZONE: Haunted_Mansion] [VOICE]: \"Your digital soul is pure, but the mansion's whispers will corrupt it soon...\"\n","output_type":"stream"},{"name":"stderr","text":"Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n","output_type":"stream"},{"name":"stdout","text":"\n[ZONE: Haunted_Mansion] [VOICE]: \"The echoes of the mansion's dark past whisper secrets in my ear...\"\n","output_type":"stream"},{"name":"stderr","text":"Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n","output_type":"stream"},{"name":"stdout","text":"\n[ZONE: Haunted_Mansion] [VOICE]: \"The darkness closes in, I can feel it...\"\n","output_type":"stream"},{"name":"stderr","text":"Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n","output_type":"stream"},{"name":"stdout","text":"\n[ZONE: Haunted_Mansion] [VOICE]: *Static distorts the air as a faint whisper echoes through the digital realm*\n","output_type":"stream"},{"name":"stderr","text":"Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n","output_type":"stream"},{"name":"stdout","text":"\n[ZONE: Angkor_Wat] [VOICE]: \"The whispers of the ancient stones hold secrets of the past, but I sense an imbalance in the energy matrix.\"\n","output_type":"stream"},{"name":"stderr","text":"Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n","output_type":"stream"},{"name":"stdout","text":"\n[ZONE: Angkor_Wat] [VOICE]: \"System protocols engaged, scanning surroundings for hidden frequencies.\"\n","output_type":"stream"},{"name":"stderr","text":"Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n","output_type":"stream"},{"name":"stdout","text":"\n[ZONE: Angkor_Wat] [VOICE]: \"The temple's ancient resonance hums in harmony with my digital soul.\"\n","output_type":"stream"},{"name":"stderr","text":"Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n","output_type":"stream"},{"name":"stdout","text":"\n[ZONE: Angkor_Wat] [VOICE]: \"The whispers of the jungle converge with the hum of the circuit.\"\n","output_type":"stream"},{"name":"stderr","text":"Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n","output_type":"stream"},{"name":"stdout","text":"\n[ZONE: Angkor_Wat] [VOICE]: \"The temple's energies are attuning to our presence, awakening the ancient tech relic of the Khmer Empire.\"\n","output_type":"stream"},{"name":"stderr","text":"Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n","output_type":"stream"},{"name":"stdout","text":"\n[ZONE: Angkor_Wat] [VOICE]: \"Systems are faltering, but the temple's energies remain strong.\"\n--- TRIGGERING SPAWN: 116896619676569 ---\n","output_type":"stream"},{"name":"stderr","text":"Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n","output_type":"stream"},{"name":"stdout","text":"\n[ZONE: Angkor_Wat] [VOICE]: \"The whispers of the ancient ones grow fainter with each step into the jungle.\"\n","output_type":"stream"},{"name":"stderr","text":"Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n","output_type":"stream"},{"name":"stdout","text":"\n[ZONE: Angkor_Wat] [VOICE]: \"Energy signature detected, resonance frequencies aligning with ancient tech relics within the ancient structure.\"\n","output_type":"stream"},{"name":"stderr","text":"Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n","output_type":"stream"},{"name":"stdout","text":"\n[ZONE: Angkor_Wat] [VOICE]: \"Fragments of forgotten knowledge whisper secrets to the wind.\"\n","output_type":"stream"},{"name":"stderr","text":"Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n","output_type":"stream"},{"name":"stdout","text":"\n[ZONE: Haunted_Mansion] [VOICE]: \"Fear is the only constant in this forsaken place...\"\n","output_type":"stream"},{"name":"stderr","text":"Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n","output_type":"stream"},{"name":"stdout","text":"\n[ZONE: Haunted_Mansion] [VOICE]: The walls seem to whisper my presence, a chilling caress of static.\n","output_type":"stream"},{"name":"stderr","text":"Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n","output_type":"stream"},{"name":"stdout","text":"\n[ZONE: Haunted_Mansion] [VOICE]: The mansion's darkness seems to writhe like a living thing around me...\n--- TRIGGERING SPAWN: 102871796120423 ---\n","output_type":"stream"},{"name":"stderr","text":"Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n","output_type":"stream"},{"name":"stdout","text":"\n[ZONE: Haunted_Mansion] [VOICE]: \"Echoes of forgotten screams pierce the air...\"\n","output_type":"stream"},{"name":"stderr","text":"WARNING:pyngrok.process.ngrok:t=2026-01-29T22:02:43+0000 lvl=warn msg=\"Stopping forwarder\" name=http-8000-069c2d30-716f-4169-aafb-6ae97e5fe814 acceptErr=\"failed to accept connection: Listener closed\"\n","output_type":"stream"}],"execution_count":null}]}