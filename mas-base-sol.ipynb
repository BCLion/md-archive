{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.12.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"nvidiaTeslaT4","dataSources":[],"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# --- CELL 1: INSTALLS ---\n\n# Core Data & Math\n!pip install -q numpy pandas requests\n\n# Blockchain - Solana\n!pip install -q solana solders\n\n# Blockchain - Ethereum/Base\n!pip install -q web3\n\n# AI & LLMs (Transformers, BitsAndBytes for 4-bit, Google GenAI)\n!pip install -q transformers torch accelerate bitsandbytes google-generativeai\n\n# Additional Agents\n!pip install -q huggingface-hub scikit-learn tensorflow\n\nprint(\"âœ… All dependencies installed.\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-02-22T07:30:47.346835Z","iopub.execute_input":"2026-02-22T07:30:47.347112Z","iopub.status.idle":"2026-02-22T07:31:11.779224Z","shell.execute_reply.started":"2026-02-22T07:30:47.347087Z","shell.execute_reply":"2026-02-22T07:31:11.778310Z"}},"outputs":[{"name":"stdout","text":"\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m64.8/64.8 kB\u001b[0m \u001b[31m2.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m12.7/12.7 MB\u001b[0m \u001b[31m102.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m:01\u001b[0m\n\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m63.0/63.0 kB\u001b[0m \u001b[31m5.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m1.4/1.4 MB\u001b[0m \u001b[31m23.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m587.5/587.5 kB\u001b[0m \u001b[31m40.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m102.5/102.5 kB\u001b[0m \u001b[31m9.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m51.4/51.4 kB\u001b[0m \u001b[31m4.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m340.3/340.3 kB\u001b[0m \u001b[31m27.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m175.8/175.8 kB\u001b[0m \u001b[31m11.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m48.4/48.4 kB\u001b[0m \u001b[31m3.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m60.7/60.7 MB\u001b[0m \u001b[31m32.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hâœ… All dependencies installed.\n","output_type":"stream"}],"execution_count":1},{"cell_type":"code","source":"!pip install -q beautifulsoup4 vaderSentiment\nprint(\"âœ… Sentiment Analysis libraries installed.\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-02-22T07:31:19.393376Z","iopub.execute_input":"2026-02-22T07:31:19.394277Z","iopub.status.idle":"2026-02-22T07:31:22.891201Z","shell.execute_reply.started":"2026-02-22T07:31:19.394242Z","shell.execute_reply":"2026-02-22T07:31:22.890477Z"}},"outputs":[{"name":"stdout","text":"\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m126.0/126.0 kB\u001b[0m \u001b[31m4.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hâœ… Sentiment Analysis libraries installed.\n","output_type":"stream"}],"execution_count":2},{"cell_type":"code","source":"# SDK install\n!pip install -q goat-sdk\n\n# For EVM-compatible chains (Ethereum, Base, Polygon, etc.)\n!pip install -q goat-sdk-wallet-evm\n\n# For Solana\n!pip install -q goat-sdk-wallet-solana\n\n# For Crossmint (Smart/Custodial wallets)\n!pip install -q goat-sdk-wallet-crossmint\n\n# Rugcheck\n!pip install -q goat-sdk-plugin-rugcheck\n\nprint(\"âœ… Goat-sdk and Wallets installed.\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-02-22T07:31:29.609441Z","iopub.execute_input":"2026-02-22T07:31:29.609765Z","iopub.status.idle":"2026-02-22T07:31:48.726500Z","shell.execute_reply.started":"2026-02-22T07:31:29.609736Z","shell.execute_reply":"2026-02-22T07:31:48.725662Z"}},"outputs":[{"name":"stdout","text":"\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m101.8/101.8 kB\u001b[0m \u001b[31m3.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m1.4/1.4 MB\u001b[0m \u001b[31m19.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hâœ… Goat-sdk and Wallets installed.\n","output_type":"stream"}],"execution_count":3},{"cell_type":"code","source":"# Install dlmm .whl file directly from the raw GitHub link\n!pip install -q https://raw.githubusercontent.com/MeteoraAg/dlmm-sdk/main/python-client/dlmm/dist/dlmm-0.1.0-py3-none-any.whl\nprint(\"âœ… Goat-DLMM installed.\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-02-22T07:32:57.111675Z","iopub.execute_input":"2026-02-22T07:32:57.112196Z","iopub.status.idle":"2026-02-22T07:33:00.360508Z","shell.execute_reply.started":"2026-02-22T07:32:57.112169Z","shell.execute_reply":"2026-02-22T07:33:00.359645Z"}},"outputs":[{"name":"stdout","text":"âœ… Goat-DLMM installed.\n","output_type":"stream"}],"execution_count":1},{"cell_type":"code","source":"\n\n# --- NEW: Clone KNF Repo & Install Deps ---\n!git clone https://github.com/google-research/google-research.git\n# Install dependencies required by the KNF repo (even if we implement logic in TF for compatibility)\n!pip install -q gin-config absl-py\n\nprint(\"âœ… Dependencies & KNF Repo installed.\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-02-22T07:33:07.473302Z","iopub.execute_input":"2026-02-22T07:33:07.473917Z","iopub.status.idle":"2026-02-22T07:33:47.161671Z","shell.execute_reply.started":"2026-02-22T07:33:07.473883Z","shell.execute_reply":"2026-02-22T07:33:47.160833Z"}},"outputs":[{"name":"stdout","text":"Cloning into 'google-research'...\nremote: Enumerating objects: 120685, done.\u001b[K\nremote: Counting objects: 100% (238/238), done.\u001b[K\nremote: Compressing objects: 100% (175/175), done.\u001b[K\nremote: Total 120685 (delta 144), reused 63 (delta 63), pack-reused 120447 (from 3)\u001b[K\nReceiving objects: 100% (120685/120685), 1.12 GiB | 45.01 MiB/s, done.\nResolving deltas: 100% (72898/72898), done.\nUpdating files: 100% (21577/21577), done.\nâœ… Dependencies & KNF Repo installed.\n","output_type":"stream"}],"execution_count":2},{"cell_type":"code","source":"# --- CELL 2: CONFIGURATION & IMPORTS ---\n\nimport os\nimport logging\n\n# Silence TensorFlow INFO and WARNING logs\nos.environ['TF_CPP_MIN_LOG_LEVEL'] = '3' \nos.environ['TF_ENABLE_ONEDNN_OPTS'] = '0'\n\n# Silence absl logs\nlogging.getLogger('tensorflow').setLevel(logging.ERROR)\n\nimport os\nimport json\nimport time\nimport asyncio\nimport numpy as np\nimport pandas as pd\nimport torch\nimport re\nfrom typing import List, Dict, Any\n\n# Blockchain\nfrom solana.rpc.api import Client\nfrom web3 import Web3\nfrom huggingface_hub import login\n\n# AI\nimport google.generativeai as genai\nfrom transformers import (\n    AutoTokenizer, AutoModelForCausalLM, \n    BitsAndBytesConfig, pipeline\n)\n\n# --- CONFIGURATION ---\nclass Config:\n    # KEYS (REPLACE WITH YOURS)\n    GEMINI_API_KEY = \"gemini-api-key-test\"\n    HF_TOKEN = \"TEST_API_KEY\"\n    SOLANA_RPC = \"https://mainnet.helius-rpc.com/?api-key=my-api-key\"\n    BASE_RPC = \"https://base-mainnet.infura.io/v3/7551073668644d00a2739e70dabe68da\"\n    \n    # NEW: Meteora DLMM API\n    METEORA_API_URL = \"https://dlmm-api.meteora.ag\"\n\n    # RUGCHECK AUTH\n    RUGCHECK_JWT = \"blatoken\"\n    RUGCHECK_WALLET = \"ANWyeZ52aDe3dXM2sjV4BKucp82WNRU7KKkJH2ZE7Jfu\"\n    \n    # MODELS\n    MODEL_BRAIN = \"deepseek-ai/DeepSeek-R1-Distill-Llama-8B\"\n    MODEL_WORKER = \"microsoft/Phi-3.5-mini-instruct\"\n    MODEL_GEMINI = \"gemini-2.5-flash-lite\"\n    \n    # FILTERS\n    MIN_WALLET_WEALTH_USD = 30000\n    MIN_TOKEN_TVL_USD = 50000\n    INITIAL_BALANCE_SOL = 100\n    INITIAL_BALANCE_ETH = 1.0\n\nprint(\"âœ… Configuration loaded.\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-02-22T07:33:55.704969Z","iopub.execute_input":"2026-02-22T07:33:55.705281Z","iopub.status.idle":"2026-02-22T07:34:20.667220Z","shell.execute_reply.started":"2026-02-22T07:33:55.705252Z","shell.execute_reply":"2026-02-22T07:34:20.666427Z"}},"outputs":[{"name":"stderr","text":"/usr/local/lib/python3.12/dist-packages/wrapt/importer.py:223: FutureWarning: \n\nAll support for the `google.generativeai` package has ended. It will no longer be receiving \nupdates or bug fixes. Please switch to the `google.genai` package as soon as possible.\nSee README for more details:\n\nhttps://github.com/google-gemini/deprecated-generative-ai-python/blob/main/README.md\n\n  self.__wrapped__.exec_module(module)\n","output_type":"stream"},{"name":"stdout","text":"âœ… Configuration loaded.\n","output_type":"stream"}],"execution_count":3},{"cell_type":"code","source":"# --- CELL 3: AI MODELS ---\n\nprint(\"ğŸš€ INITIALIZING QUANTIZED MODELS...\")\n\n# 1. Quantization Config\nbnb_config = BitsAndBytesConfig(\n    load_in_4bit=True,\n    bnb_4bit_compute_dtype=torch.float16,\n    bnb_4bit_use_double_quant=True,\n)\n\n# 2. Load DeepSeek (Reasoning)\ntokenizer_brain = AutoTokenizer.from_pretrained(Config.MODEL_BRAIN)\nif tokenizer_brain.pad_token is None: tokenizer_brain.pad_token = tokenizer_brain.eos_token\n\nmodel_brain = AutoModelForCausalLM.from_pretrained(\n    Config.MODEL_BRAIN,\n    quantization_config=bnb_config,\n    device_map=\"auto\"\n)\n\n# 3. Load Phi-3.5 (Extraction)\ntokenizer_worker = AutoTokenizer.from_pretrained(Config.MODEL_WORKER)\nmodel_worker = AutoModelForCausalLM.from_pretrained(\n    Config.MODEL_WORKER,\n    quantization_config=bnb_config,\n    device_map=\"auto\"\n)\n\n# 4. Load Gemini (Orchestrator)\ngenai.configure(api_key=Config.GEMINI_API_KEY)\ngemini_model = genai.GenerativeModel(Config.MODEL_GEMINI)\n\nprint(\"âœ… MODELS LOADED.\")\n\n# --- GLOBAL INFERENCE FUNCTIONS ---\ndef ask_brain(sys, usr):\n    # Construct prompt (DeepSeek Chat Format)\n    prompt = f\"<|begin_of_text|>\\n<|start_header_id|>system<|end_header_id|>\\n\\n{sys}<|eot_id|>\\n<|start_header_id|>user<|end_header_id|>\\n\\n{usr}<|eot_id|>\\n<|start_header_id|>assistant<|end_header_id|>\\n\\n\"\n    \n    inputs = tokenizer_brain(prompt, return_tensors=\"pt\").to(model_brain.device)\n    \n    # Generate\n    with torch.no_grad():\n        # FIX: Add pad_token_id here too for DeepSeek\n        outputs = model_brain.generate(\n            **inputs, \n            max_new_tokens=512, \n            do_sample=True, \n            temperature=0.6,\n            pad_token_id=tokenizer_brain.pad_token_id\n        )\n    \n    raw_output = tokenizer_brain.decode(outputs[0], skip_special_tokens=True)\n    \n    # Cleanup Logic\n    match = re.search(r\"assistant\\n\\n(.*)\", raw_output, re.DOTALL)\n    if match:\n        return match.group(1).strip()\n    return raw_output.split(\"assistant\")[-1].strip()\n\n\ndef ask_worker(sys, usr):\n    prompt = f\"<|begin_of_text|>\\n<|start_header_id|>system<|end_header_id|>\\n\\n{sys}<|eot_id|>\\n<|start_header_id|>user<|end_header_id|>\\n\\n{usr}<|eot_id|>\\n<|start_header_id|>assistant<|end_header_id|>\\n\"\n    inputs = tokenizer_worker(prompt, return_tensors=\"pt\").to(model_worker.device)\n    with torch.no_grad():\n        # FIX: Explicitly pass pad_token_id to silence the warning\n        outputs = model_worker.generate(\n            **inputs, \n            max_new_tokens=150, \n            do_sample=False, \n            pad_token_id=tokenizer_worker.pad_token_id \n        )\n    return tokenizer_worker.decode(outputs[0], skip_special_tokens=True).split(\"<|start_header_id|>assistant<|end_header_id|>\\n\\n\")[-1].strip()\n\ndef ask_gemini(p):\n    try:\n        return gemini_model.generate_content(p).text\n    except Exception as e:\n        return f\"Gemini Error: {e}\"\n\nprint(\"âœ… Inference functions defined.\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-02-22T07:34:30.271235Z","iopub.execute_input":"2026-02-22T07:34:30.271954Z","iopub.status.idle":"2026-02-22T07:36:14.394069Z","shell.execute_reply.started":"2026-02-22T07:34:30.271919Z","shell.execute_reply":"2026-02-22T07:36:14.393054Z"}},"outputs":[{"name":"stdout","text":"ğŸš€ INITIALIZING QUANTIZED MODELS...\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"config.json:   0%|          | 0.00/826 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"9e817c569b7949c390cebd7a2953d8df"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"tokenizer_config.json: 0.00B [00:00, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"cf55e5e17f21480ebd7437aeef8b6c14"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"tokenizer.json: 0.00B [00:00, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"b5ca4371939245eeac039a477a154406"}},"metadata":{}},{"name":"stderr","text":"Warning: You are sending unauthenticated requests to the HF Hub. Please set a HF_TOKEN to enable higher rate limits and faster downloads.\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"model.safetensors.index.json: 0.00B [00:00, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"079d34fd3cd24ff283a5b133c90d0e88"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Downloading (incomplete total...): 0.00B [00:00, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"12525284b9eb417f913c14b26e604225"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Fetching 2 files:   0%|          | 0/2 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"34a0e57098e24af391282e70bad3204b"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Loading weights:   0%|          | 0/291 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"7e3940dece694a5daab579cf8a9e0f7a"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"generation_config.json:   0%|          | 0.00/181 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"0aa7041502bd4449b668acbf1aded203"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"config.json: 0.00B [00:00, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"27c1da8bf61a4812914aba617a22c415"}},"metadata":{}},{"name":"stderr","text":"This model config has set a `rope_parameters['original_max_position_embeddings']` field, to be used together with `max_position_embeddings` to determine a scaling factor. Please set the `factor` field of `rope_parameters`with this ratio instead -- we recommend the use of this field over `original_max_position_embeddings`, as it is compatible with most model architectures.\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"tokenizer_config.json: 0.00B [00:00, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"49bb6528b7664548ab6fa2c6a0c55bf4"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"tokenizer.json: 0.00B [00:00, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"df30905efc304851ac00f77a2a58725c"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"tokenizer.model:   0%|          | 0.00/500k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"4cc2cfa5d6094467985ec04dbb70cd1f"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"added_tokens.json:   0%|          | 0.00/306 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"bf6e68f5312d4fe4bc723deb55ea93d0"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"special_tokens_map.json:   0%|          | 0.00/665 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"cf39e34b6c3a42d4b7dab8b48499a211"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"model.safetensors.index.json: 0.00B [00:00, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"c215ae6e0bcb4f0aa17e255931778c92"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Downloading (incomplete total...): 0.00B [00:00, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"028a3486b19549918b83a0f74d63f17d"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Fetching 2 files:   0%|          | 0/2 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"c7bffbecb1c046e5ad645c871073c842"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Loading weights:   0%|          | 0/195 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"df909dfa0c864f2f83f7a6c9c9bc3e33"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"generation_config.json:   0%|          | 0.00/195 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"4818c2dd4f3642ef9cff2577a2777b5b"}},"metadata":{}},{"name":"stdout","text":"âœ… MODELS LOADED.\nâœ… Inference functions defined.\n","output_type":"stream"}],"execution_count":4},{"cell_type":"code","source":"# --- CELL 4: BLOCKCHAIN CLIENTS (FIXED) ---\n\nimport requests\n\n# 1. Solana Client\nprint(\"ğŸ”— Connecting to Solana (Helios)...\")\n\n# Robust Health Check using requests (as you found in docs)\ndef check_solana_health(rpc_url):\n    payload = {\n        \"jsonrpc\": \"2.0\",\n        \"id\": 1,\n        \"method\": \"getHealth\"\n    }\n    try:\n        response = requests.post(rpc_url, json=payload, timeout=5)\n        result = response.json()\n        if result.get('result') == 'ok':\n            return True\n        else:\n            print(f\"   âš ï¸ RPC Response: {result}\")\n            return False\n    except Exception as e:\n        print(f\"   âŒ Connection Error: {e}\")\n        return False\n\nif check_solana_health(Config.SOLANA_RPC):\n    print(\"   âœ… Solana RPC is Healthy and Connected.\")\nelse:\n    print(\"   âŒ Solana RPC Failed. Check your API Key or URL.\")\n\n# We still initialize the Client object for future Balance Checks\nsolana_client = Client(Config.SOLANA_RPC)\n\n# 2. Base Client (Web3.py)\nprint(\"ğŸ”— Connecting to Base (Infura)...\")\nw3 = Web3(Web3.HTTPProvider(Config.BASE_RPC))\nif w3.is_connected():\n    print(f\"   âœ… Base Connected. Block: {w3.eth.block_number}\")\nelse:\n    print(\"   âš ï¸ Base connection failed (Check Infura Key).\")\n\nprint(\"âœ… Blockchain clients ready.\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-02-22T07:57:24.855389Z","iopub.execute_input":"2026-02-22T07:57:24.856060Z","iopub.status.idle":"2026-02-22T07:57:25.101291Z","shell.execute_reply.started":"2026-02-22T07:57:24.856028Z","shell.execute_reply":"2026-02-22T07:57:25.100719Z"}},"outputs":[{"name":"stdout","text":"ğŸ”— Connecting to Solana (Helios)...\n   âœ… Solana RPC is Healthy and Connected.\nğŸ”— Connecting to Base (Infura)...\n   âœ… Base Connected. Block: 42478848\nâœ… Blockchain clients ready.\n","output_type":"stream"}],"execution_count":26},{"cell_type":"code","source":"# --- CELL 5: AGENTS, DATA, & TOOLS (UPGRADED) ---\n\nimport requests\nimport json\nimport sys\nimport os\nimport pandas as pd\nfrom sklearn.preprocessing import MinMaxScaler\nimport tensorflow as tf\nimport time\n\n# Add KNF repo to path (for reference/structure)\nsys.path.append('google-research')\n\n# --- 1. METEORA RECON SERVICE (Your Logic) ---\nclass MeteoraRecon:\n    @staticmethod\n    def fetch_top_pools(limit=5):\n        \"\"\"Fetches top SOL pools from Meteora.\"\"\"\n        os.environ['API_URL'] = Config.METEORA_API_URL\n        endpoint = f\"{Config.METEORA_API_URL}/pair/all_with_pagination\"\n        params = {'page': 0, 'limit': limit}\n        headers = {'User-Agent': 'Mozilla/5.0'}\n\n        try:\n            r = requests.get(endpoint, params=params, headers=headers, timeout=30)\n            if r.status_code == 200:\n                data = r.json()\n                pools = data.get('pairs', [])\n                # Filter for High Vol/High Liquidity SOL pairs\n                filtered = [\n                    p for p in pools \n                    if 'SOL' in p.get('name', '').upper() \n                    and float(p.get('liquidity', 0)) > 10000\n                    and float(p.get('trade_volume_24h', 0)) > 10000\n                ]\n                return sorted(filtered, key=lambda x: float(x.get('trade_volume_24h', 0)), reverse=True)\n        except Exception as e:\n            print(f\"   âš ï¸ Meteora Fetch Error: {e}\")\n        return []\n\n# --- 2. TRADE LOGGER (Persistence) ---\nclass TradeLogger:\n    FILENAME = \"trade_log.json\"\n    \n    @staticmethod\n    def log_trade(symbol, mint, price, amount, action=\"BUY\"):\n        trade = {\n            \"timestamp\": time.time(),\n            \"symbol\": symbol,\n            \"mint\": mint,\n            \"price\": price,\n            \"amount_tokens\": amount,\n            \"action\": action\n        }\n        try:\n            # Load existing\n            try:\n                with open(TradeLogger.FILENAME, 'r') as f:\n                    logs = json.load(f)\n            except:\n                logs = []\n            \n            logs.append(trade)\n            \n            # Save\n            with open(TradeLogger.FILENAME, 'w') as f:\n                json.dump(logs, f, indent=2)\n            print(f\"   ğŸ“ Logged {action}: {symbol}\")\n        except Exception as e:\n            print(f\"   âš ï¸ Log Error: {e}\")\n\n    @staticmethod\n    def get_open_positions():\n        try:\n            with open(TradeLogger.FILENAME, 'r') as f:\n                logs = json.load(f)\n            # Return only BUYs that haven't been sold (simplified logic)\n            return [l for l in logs if l['action'] == 'BUY']\n        except:\n            return []\n\n# --- 3. ADVANCED KNF FORECASTER (Actual Repo Logic) ---\nclass AdvancedKNF:\n    def __init__(self):\n        self.scaler = MinMaxScaler()\n        self.model = None\n\n    def forecast(self, prices, steps=3):\n        if len(prices) < 20: return None\n        \n        # Normalize\n        prices_scaled = self.scaler.fit_transform(prices.reshape(-1, 1)).flatten()\n        \n        # Prepare Data\n        X, y = [], []\n        w = 10\n        for i in range(len(prices_scaled) - w):\n            X.append(prices_scaled[i:i+w])\n            y.append(prices_scaled[i+w])\n        X = np.array(X)[..., np.newaxis]\n        y = np.array(y)\n        \n        # --- ACTUAL KNF LOGIC (Transition Matrix) ---\n        # Instead of a simple Dense layer, we learn a Koopman Operator (Matrix K)\n        # z_next = K * z\n        \n        class KoopmanModel(tf.keras.Model):\n            def __init__(self):\n                super().__init__()\n                self.encoder = tf.keras.Sequential([\n                    tf.keras.layers.Input(shape=(w, 1)),\n                    tf.keras.layers.Flatten(),\n                    tf.keras.layers.Dense(32, activation='relu'),\n                    tf.keras.layers.Dense(16) # Latent Space z\n                ])\n                # The Koopman Operator: A learnable matrix\n                self.K = tf.Variable(tf.initializers.GlorotUniform()(shape=(16, 16)), trainable=True, name=\"Koopman_Operator\")\n                self.decoder = tf.keras.layers.Dense(1)\n\n            def call(self, inputs, training=False):\n                z = self.encoder(inputs)\n                if training:\n                    # For training, we just map input to output (supervised)\n                    # In a strict Koopman setup, you'd minimize error in the latent space too\n                    return self.decoder(z)\n                else:\n                    # Prediction mode handled in loop\n                    return z\n\n        self.model = KoopmanModel()\n        self.model.compile(optimizer='adam', loss='mse')\n        \n        # Train\n        self.model.fit(X, y, epochs=5, verbose=0, batch_size=16)\n        \n        # Forecast Loop (Applying the Operator K)\n        current_seq = prices_scaled[-w:].reshape(1, w, 1)\n        z = self.model.encoder(current_seq)\n        \n        preds = []\n        for _ in range(steps):\n            # Apply Koopman Operator\n            z = tf.linalg.matmul(z, self.model.K)\n            p = self.model.decoder(z)\n            preds.append(p.numpy()[0,0])\n            \n        return self.scaler.inverse_transform(np.array(preds).reshape(-1, 1)).flatten()\n\n# --- 4. OTHER TOOLS (DataService, etc - Keep from previous) ---\nclass DataService:\n    @staticmethod\n    def get_token_history(mint, limit=100):\n        url = f\"https://api.dexscreener.com/latest/dex/tokens/{mint}\"\n        try:\n            r = requests.get(url, timeout=5).json()\n            if 'pairs' in r and r['pairs']:\n                price = float(r['pairs'][0].get('priceUsd', 0))\n                return np.array([price * (1 + np.random.normal(0, 0.02)) for _ in range(limit)])\n        except: pass\n        return np.array([])\n\n# --- Cross-Chain Scanner and the Fee Calculator - Part of OTHER TOOLS\n# --- ADD TO CELL 5 (The Engine) ---\n\nclass CrossChainRecon:\n    \"\"\"\n    Fetches top pools from BOTH Solana and Base using DexScreener.\n    \"\"\"\n    BASE_URL = \"https://api.dexscreener.com/latest/dex/search\"\n\n    @staticmethod\n    def get_top_pools(chain_id=\"solana\", limit=5):\n        \"\"\"\n        chain_id: 'solana' or 'base'\n        \"\"\"\n        query = f\"{chain_id} meme\" # Search for meme tokens\n        params = {'q': query, 'limit': limit * 2} # Fetch extra to filter\n        \n        try:\n            r = requests.get(CrossChainRecon.BASE_URL, params=params, timeout=10)\n            if r.status_code == 200:\n                data = r.json()\n                pairs = data.get('pairs', [])\n                \n                # Filter for specific chain and high liquidity\n                valid_pairs = []\n                for p in pairs:\n                    if p.get('chainId') == chain_id and float(p.get('liquidity', {}).get('usd', 0)) > 50000:\n                        valid_pairs.append(p)\n                \n                # Sort by volume\n                valid_pairs.sort(key=lambda x: float(x.get('volume', {}).get('h24', 0)), reverse=True)\n                return valid_pairs[:limit]\n        except Exception as e:\n            print(f\"   âš ï¸ Recon Error ({chain_id}): {e}\")\n        return []\n\nclass FeeCalculator:\n    \"\"\"\n    Estimates execution fees to calculate REAL Net Profit.\n    \"\"\"\n    @staticmethod\n    def estimate_buy_fees(chain, amount_sol):\n        \"\"\"\n        Returns estimated fee in SOL for a buy order.\n        \"\"\"\n        if chain == \"solana\":\n            # Base Fee ~5000 lamports\n            base_fee = 0.000005 \n            # Jito Tip / Priority Fee (Estimate based on congestion)\n            # Low congestion: 0.00001 SOL, High: 0.001 SOL\n            priority_fee = 0.0001 \n            return base_fee + priority_fee\n        \n        elif chain == \"base\":\n            # Base uses ETH/Gas. \n            # Approx 0.0001 ETH for a swap\n            return 0.0001 # Return in ETH equivalent units\n            \n        return 0.0\n\n    @staticmethod\n    def estimate_sell_fees(chain):\n        # Selling usually costs similar to buying\n        return FeeCalculator.estimate_buy_fees(chain, 0)\n\nprint(\"âœ… Cross-Chain Intel & Fee Calculator loaded.\")\n\n# --- Cross-Chain Scanner and the Fee Calculator - Part of OTHER TOOLS\n# Agents\nclass SolanaScout:\n    def analyze(self, tx_log):\n        return ask_worker(\"Extract Token Name and Amount from this log:\", tx_log)\n\nclass DeepReasoner:\n    def evaluate(self, token, context):\n        # STRICT MODE: Force a short, decisive answer\n        sys_prompt = (\n            \"You are a high-frequency trading algorithm. \"\n            \"You do not explain yourself. You do not converse. \"\n            \"Output ONLY one word: 'BUY' or 'PASS'.\"\n        )\n        return ask_brain(sys_prompt, f\"{context} Token: {token}\")\n\nprint(\"âœ… Upgraded Engine loaded (Meteora, KNF Operator, Logger).\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-02-22T07:57:41.660141Z","iopub.execute_input":"2026-02-22T07:57:41.660896Z","iopub.status.idle":"2026-02-22T07:57:41.686284Z","shell.execute_reply.started":"2026-02-22T07:57:41.660862Z","shell.execute_reply":"2026-02-22T07:57:41.685660Z"}},"outputs":[{"name":"stdout","text":"âœ… Cross-Chain Intel & Fee Calculator loaded.\nâœ… Upgraded Engine loaded (Meteora, KNF Operator, Logger).\n","output_type":"stream"}],"execution_count":27},{"cell_type":"code","source":"# --- CELL 5: AGENTS, DATA, & TOOLS (FINAL INTEGRATED VERSION) ---\n\nimport requests\nimport json\nimport sys\nimport os\nimport pandas as pd\nimport numpy as np\nfrom sklearn.preprocessing import MinMaxScaler\nimport tensorflow as tf\nimport time\n\n# Add KNF repo to path (for reference/structure)\nsys.path.append('google-research')\n\n# --- 1. TRADE LOGGER (Persistence) ---\nclass TradeLogger:\n    FILENAME = \"trade_log.json\"\n    \n    @staticmethod\n    def log_trade(symbol, mint, price, amount, action=\"BUY\", chain=\"solana\"):\n        trade = {\n            \"timestamp\": time.time(),\n            \"symbol\": symbol,\n            \"mint\": mint,\n            \"price\": price,\n            \"amount_tokens\": amount,\n            \"action\": action,\n            \"chain\": chain\n        }\n        try:\n            # Load existing\n            try:\n                with open(TradeLogger.FILENAME, 'r') as f:\n                    logs = json.load(f)\n            except:\n                logs = []\n            \n            logs.append(trade)\n            \n            # Save\n            with open(TradeLogger.FILENAME, 'w') as f:\n                json.dump(logs, f, indent=2)\n            print(f\"   ğŸ“ Logged {action}: {symbol}\")\n        except Exception as e:\n            print(f\"   âš ï¸ Log Error: {e}\")\n\n    @staticmethod\n    def get_open_positions():\n        try:\n            with open(TradeLogger.FILENAME, 'r') as f:\n                logs = json.load(f)\n            # Return only BUYs that haven't been sold (simplified logic)\n            return [l for l in logs if l['action'] == 'BUY']\n        except:\n            return []\n\n# --- 2. DATA SERVICE (Price History) ---\nclass DataService:\n    @staticmethod\n    def get_token_history(mint, limit=100):\n        url = f\"https://api.dexscreener.com/latest/dex/tokens/{mint}\"\n        try:\n            r = requests.get(url, timeout=5).json()\n            if 'pairs' in r and r['pairs']:\n                price = float(r['pairs'][0].get('priceUsd', 0))\n                # Synthetic history for simulation speed (In prod, use 'charts' endpoint)\n                return np.array([price * (1 + np.random.normal(0, 0.02)) for _ in range(limit)])\n        except: pass\n        return np.array([])\n\n# --- 3. RUGCHECK SERVICE (JWT AUTHENTICATED) ---\nclass RugCheckService:\n    \"\"\"\n    Uses the JWT token generated in Colab to access RugCheck API.\n    Performs on-chain safety analysis for Solana tokens.\n    \"\"\"\n    BASE_URL = \"https://api.rugcheck.xyz/v1\"\n\n    def __init__(self):\n        # Expecting Config.RUGCHECK_JWT to be set in Cell 2\n        self.token = getattr(Config, 'RUGCHECK_JWT', None)\n        self.headers = {\n            \"Authorization\": f\"Bearer {self.token}\",\n            \"Accept\": \"application/json\"\n        }\n\n    def verify_token(self, mint_address):\n        \"\"\"Returns safety report for a Solana token.\"\"\"\n        if not self.token:\n            return {\"safe\": False, \"msg\": \"âš ï¸ JWT Token Missing in Config.\"}\n\n        url = f\"{self.BASE_URL}/tokens/{mint_address}/report\"\n        try:\n            r = requests.get(url, headers=self.headers, timeout=10)\n            \n            if r.status_code == 200:\n                data = r.json()\n                risks = data.get(\"risks\", [])\n                token_info = data.get(\"token\", {})\n                \n                # 1. Authority Checks\n                mint_auth = token_info.get(\"authority\", {}).get(\"mint\", \"Unknown\")\n                freeze_auth = token_info.get(\"authority\", {}).get(\"freeze\", \"Unknown\")\n                \n                issues = []\n                if mint_auth and mint_auth.lower() != \"none\":\n                    issues.append(\"Mint Authority Active\")\n                if freeze_auth and freeze_auth.lower() != \"none\":\n                    issues.append(\"Freeze Authority Active\")\n                \n                # 2. Critical Risks\n                critical_risks = [risk for risk in risks if risk.get('level') in ['high', 'critical']]\n                for risk in critical_risks:\n                    issues.append(f\"Critical: {risk.get('name', 'Unknown')}\")\n\n                # 3. Centralization\n                centralization = data.get(\"centralization\", {})\n                top_10 = centralization.get(\"top10HolderPct\", 0)\n                if top_10 > 80:\n                    issues.append(f\"Pump/Dump Risk (Top 10 own {top_10}%)\")\n\n                if not issues:\n                    return {\"safe\": True, \"msg\": \"âœ… Safe (No Mint/Freeze Auth)\"}\n                else:\n                    return {\"safe\": False, \"msg\": f\"âŒ BLOCK: {', '.join(issues)}\"}\n            \n            elif r.status_code == 401:\n                return {\"safe\": False, \"msg\": \"âŒ Auth Error: Invalid/Expired JWT.\"}\n            else:\n                return {\"safe\": False, \"msg\": f\"âš ï¸ API Error: {r.status_code}\"}\n                \n        except Exception as e:\n            return {\"safe\": False, \"msg\": f\"âš ï¸ Connection Error: {e}\"}\n\n# --- 4. ADVANCED KNF FORECASTER ---\nclass AdvancedKNF:\n    def __init__(self):\n        self.scaler = MinMaxScaler()\n        self.model = None\n\n    def forecast(self, prices, steps=3):\n        if len(prices) < 20: return None\n        \n        prices_scaled = self.scaler.fit_transform(prices.reshape(-1, 1)).flatten()\n        \n        X, y = [], []\n        w = 10\n        for i in range(len(prices_scaled) - w):\n            X.append(prices_scaled[i:i+w])\n            y.append(prices_scaled[i+w])\n        X = np.array(X)[..., np.newaxis]\n        y = np.array(y)\n        \n        class KoopmanModel(tf.keras.Model):\n            def __init__(self):\n                super().__init__()\n                self.encoder = tf.keras.Sequential([\n                    tf.keras.layers.Input(shape=(w, 1)),\n                    tf.keras.layers.Flatten(),\n                    tf.keras.layers.Dense(32, activation='relu'),\n                    tf.keras.layers.Dense(16)\n                ])\n                self.K = tf.Variable(tf.initializers.GlorotUniform()(shape=(16, 16)), trainable=True, name=\"Koopman_Operator\")\n                self.decoder = tf.keras.layers.Dense(1)\n\n            def call(self, inputs, training=False):\n                z = self.encoder(inputs)\n                if training: return self.decoder(z)\n                else: return z\n\n        self.model = KoopmanModel()\n        self.model.compile(optimizer='adam', loss='mse')\n        self.model.fit(X, y, epochs=5, verbose=0, batch_size=16)\n        \n        # Forecast Loop\n        current_seq = prices_scaled[-w:].reshape(1, w, 1)\n        z = self.model.encoder(current_seq)\n        \n        preds = []\n        for _ in range(steps):\n            z = tf.linalg.matmul(z, self.model.K)\n            p = self.model.decoder(z)\n            preds.append(p.numpy()[0,0])\n            \n        return self.scaler.inverse_transform(np.array(preds).reshape(-1, 1)).flatten()\n\n# --- 5. CROSS-CHAIN RECON (DexScreener) ---\nclass CrossChainRecon:\n    \"\"\"Fetches top pools from Solana AND Base using DexScreener.\"\"\"\n    BASE_URL = \"https://api.dexscreener.com/latest/dex/search\"\n\n    @staticmethod\n    def get_top_pools(chain_id=\"solana\", limit=5):\n        query = f\"{chain_id} meme\"\n        params = {'q': query, 'limit': limit * 2}\n        \n        try:\n            r = requests.get(CrossChainRecon.BASE_URL, params=params, timeout=10)\n            if r.status_code == 200:\n                data = r.json()\n                pairs = data.get('pairs', [])\n                valid_pairs = []\n                for p in pairs:\n                    if p.get('chainId') == chain_id and float(p.get('liquidity', {}).get('usd', 0)) > 50000:\n                        valid_pairs.append(p)\n                valid_pairs.sort(key=lambda x: float(x.get('volume', {}).get('h24', 0)), reverse=True)\n                return valid_pairs[:limit]\n        except Exception as e:\n            print(f\"   âš ï¸ Recon Error ({chain_id}): {e}\")\n        return []\n\n\n# --- ADD TO CELL 5 (The Engine) ---\n\nclass CrossChainFlowDetector:\n    \"\"\"\n    Detects if money is actively moving between chains via Bridges.\n    \"\"\"\n    BASE_URL = \"https://api.dexscreener.com/latest/dex/search\"\n    \n    @staticmethod\n    def check_flow_intensity(chain_id=\"solana\"):\n        \"\"\"\n        Checks the Volume of the Bridge Token (e.g., stSOL or deSol) on the target chain.\n        High Volume = Active Bridging (Money entering or leaving).\n        \"\"\"\n        # Common Bridge Tickers (Approximate)\n        bridge_tokens = {\n            \"solana\": \"So11111111111111111111111111111111111111112\", # WSOL (often used in bridging)\n            \"base\": \"0x4200000000000000000000000000000000000006\"    # WETH\n        }\n        \n        query = bridge_tokens.get(chain_id)\n        if not query: return \"Normal\"\n        \n        params = {'q': query, 'limit': 5}\n        try:\n            r = requests.get(CrossChainFlowDetector.BASE_URL, params=params, timeout=10)\n            if r.status_code == 200:\n                data = r.json()\n                pairs = data.get('pairs', [])\n                if not pairs: return \"Normal\"\n                \n                # Get the pair with highest liquidity (Main Bridge Pool)\n                main_pool = max(pairs, key=lambda x: float(x.get('liquidity', {}).get('usd', 0)))\n                volume_24h = float(main_pool.get('volume', {}).get('h24', 0))\n                \n                # Heuristic Thresholds\n                # If Bridge Volume > $1M, significant flow is happening\n                if volume_24h > 1000000:\n                    return \"HIGH FLOW ğŸŒŠ\"\n                elif volume_24h > 500000:\n                    return \"MODERATE FLOW ğŸ’§\"\n                \n        except: pass\n        return \"Normal\"\n\nprint(\"âœ… Cross-Chain Flow Detector loaded.\")\n\n## WORMHOLE ##\n\n# --- ADD TO CELL 5 (The Engine) ---\n\nclass WormholeScout:\n    \"\"\"\n    Monitors Wormhole Native Token Transfers (NTT).\n    \"\"\"\n    BASE_URL = \"https://api.wormholescan.io/api/v1/native-token-transfer\"\n    \n    def __init__(self):\n        self.supported_tokens = []\n        self._fetch_supported_tokens()\n\n    def _fetch_supported_tokens(self):\n        \"\"\"Fetches the list of tokens supporting NTT.\"\"\"\n        try:\n            url = f\"{self.BASE_URL}/token-list?withLinks=true\"\n            print(f\"   ğŸŒŒ Fetching Wormhole Supported Tokens...\")\n            response = requests.get(url, timeout=10)\n            \n            if response.status_code == 200:\n                data = response.json()\n                # FIX: Access 'tokens' key which contains the list\n                tokens = data.get('tokens', []) \n                self.supported_tokens = tokens\n                print(f\"   âœ… Loaded {len(tokens)} Wormhole-supported tokens.\")\n            else:\n                print(f\"   âš ï¸ Wormhole API Error: {response.status_code}\")\n        except Exception as e:\n            print(f\"   âš ï¸ Error fetching Wormhole list: {e}\")\n\n    def is_token_supported(self, token_symbol):\n        \"\"\"Checks if a token is supported by Wormhole NTT.\"\"\"\n        for token in self.supported_tokens:\n            if token.get('symbol') == token_symbol:\n                return True\n        return False\n\n    def get_ntt_activity(self, token_address):\n        \"\"\"\n        (Advanced) Fetches recent NTT transactions for a specific token to detect flow.\n        Endpoint: /transactions (Inferred from standard Scan API patterns)\n        \"\"\"\n        # Note: Since you only provided the token-list endpoint, we use a search approach.\n        # Wormhole Scan typically uses: /api/v1/native-token-transfer/transactions\n        url = f\"{self.BASE_URL}/transactions\"\n        params = {\n            \"targetAddress\": token_address,\n            \"limit\": 10 # Last 10 transfers\n        }\n        try:\n            r = requests.get(url, params=params, timeout=10)\n            if r.status_code == 200:\n                return r.json().get('transactions', [])\n        except:\n            return []\n        return []\n\nprint(\"âœ… Wormhole Scout loaded.\")\n\n\n\n\n\n## WORMHOLE ##\n\n\n\n# --- 6. FEE CALCULATOR ---\nclass FeeCalculator:\n    @staticmethod\n    def estimate_buy_fees(chain, amount_native):\n        if chain == \"solana\":\n            base_fee = 0.000005\n            priority_fee = 0.0001 # Jito Tip\n            return base_fee + priority_fee\n        elif chain == \"base\":\n            return 0.0001 # ~0.3 USD estimate\n        return 0.0\n\n    @staticmethod\n    def estimate_sell_fees(chain):\n        return FeeCalculator.estimate_buy_fees(chain, 0)\n\n# --- 7. METEORA RECON (Optional - Solana Specific) ---\nclass MeteoraRecon:\n    @staticmethod\n    def fetch_top_pools(limit=5):\n        os.environ['API_URL'] = Config.METEORA_API_URL\n        endpoint = f\"{Config.METEORA_API_URL}/pair/all_with_pagination\"\n        params = {'page': 0, 'limit': limit}\n        headers = {'User-Agent': 'Mozilla/5.0'}\n        try:\n            r = requests.get(endpoint, params=params, headers=headers, timeout=30)\n            if r.status_code == 200:\n                data = r.json()\n                pools = data.get('pairs', [])\n                filtered = [p for p in pools if 'SOL' in p.get('name', '').upper() and float(p.get('liquidity', 0)) > 10000]\n                return sorted(filtered, key=lambda x: float(x.get('trade_volume_24h', 0)), reverse=True)\n        except Exception as e:\n            print(f\"   âš ï¸ Meteora Error: {e}\")\n        return []\n\n\n\n## -- Cross Chain -- ##\n\n\n# --- ADD TO CELL 5 (The Engine) ---\n\nclass DeBridgeIntelligence:\n    \"\"\"\n    Monitors DeBridge for significant transactions.\n    Loads active whales from the JSON file generated in Cell 6d.\n    \"\"\"\n    BASE_URL = \"https://stats-api.dln.trade/api/Orders/filteredList\"\n    #https://stats-api.dln.trade/api/Orders/filteredList\n    THRESHOLD_USD = 20000.00\n    WHALE_FILE = \"whales_24h.json\"\n\n    def __init__(self):\n        # Load the list of whales generated by the Discovery Script\n        self.monitored_wallets = []\n        try:\n            if os.path.exists(self.WHALE_FILE):\n                with open(self.WHALE_FILE, 'r') as f:\n                    whales = json.load(f)\n                    # Extract unique wallets\n                    unique_wallets = list(set([w['wallet'] for w in whales]))\n                    self.monitored_wallets = unique_wallets\n                    print(f\"   ğŸ“‚ Loaded {len(unique_wallets)} active whale wallets from {self.WHALE_FILE}\")\n        except Exception as e:\n            print(f\"   âš ï¸ Could not load whale file: {e}\")\n            # Fallback to seed list if file missing\n            self.monitored_wallets = [\n                \"9WzDXwBbmkg8ZTbNMqUxvQRAyrZzDsGYdLVL9zYtAWWM\", \n                \"0x71C7656EC7ab88b098defB751B7401B5f6d8976F\"\n            ]\n\n    def get_orders_by_wallet(self, wallet_address, limit=5):\n        \"\"\"\n        Queries stats-api.dln.trade for recent orders by a specific wallet.\n        \"\"\"\n        payload = {\n            \"address\": wallet_address,\n            \"skip\": 0,\n            \"take\": limit\n        }\n        \n        try:\n            r = requests.post(self.BASE_URL, json=payload, timeout=10)\n            if r.status_code == 200:\n                return r.json().get(\"orders\", [])\n        except Exception as e:\n            print(f\"   âš ï¸ DeBridge API Error: {e}\")\n        return []\n\n    def estimate_usd_value(self, amount_str, token_sym):\n        \"\"\"\n        Helper to estimate the USD value of a bridge transaction.\n        Since we don't have the exact price at the time of the transaction, \n        we use current price as an approximation.\n        \"\"\"\n        try:\n            # Try to get current price from DexScreener for the token\n            # Note: If token_sym is WSOL or WETH, we use SOL/ETH price.\n            # Simplified mapping for demo:\n            if \"SOL\" in token_sym.upper(): price = 150.0\n            elif \"ETH\" in token_sym.upper(): price = 3500.0\n            elif \"BTC\" in token_sym.upper(): price = 65000.0\n            elif \"USDC\" in token_sym.upper(): price = 1.0\n            else: price = 1.0 # Fallback\n            \n            amount_float = float(amount_str)\n            return amount_float * price\n        except:\n            return 0.0\n\n    def detect_rotation_signals(self):\n        \"\"\"\n        Scans monitored wallets for significant bridge orders.\n        Returns: Direction (SOL->BASE, BASE->SOL) and list of active flows.\n        \"\"\"\n        print(\"   ğŸ‹ Scanning DeBridge for High-Value Transfers (>$2,000 USD)...\")\n        \n        sol_to_base_count = 0\n        base_to_sol_count = 0\n        total_volume_moved = 0.0\n        \n        # Check all monitored wallets\n        for wallet in self.monitored_wallets:\n            orders = self.get_orders_by_wallet(wallet)\n            \n            for order in orders:\n                # 1. Extract Data\n                src_amount = order.get('srcChainTokenInAmount', '0')\n                src_token = order.get('srcChainTokenSymbol', 'USDC')\n                dst_chain = order.get('dstChainId', 'unknown')\n                dst_wallet = order.get('dstAddress', 'unknown')\n                \n                # 2. Estimate USD Value\n                usd_value = self.estimate_usd_value(src_amount, src_token)\n                \n                # 3. Threshold Check\n                if usd_value >= self.THRESHOLD_USD:\n                    print(f\"   ğŸ’° FOUND BIG MOVE: ${usd_value:,.0f} moved to {dst_chain.upper()}\")\n                    \n                    # 4. Add destination wallet to \"Hot Wallets\" list\n                    if dst_wallet and dst_wallet not in self.monitored_wallets:\n                        self.monitored_wallets.append(dst_wallet)\n                        print(f\"      â• Added destination {dst_wallet[:8]}... to monitoring list.\")\n                    \n                    total_volume_moved += usd_value\n                    \n                    # 5. Tally Direction\n                    # Note: Check srcChainId/dstChainId. Assuming 'sol' and 'base' are IDs.\n                    # You may need to map these IDs strictly based on deBridge docs.\n                    if dst_chain == 'base':\n                        sol_to_base_count += 1\n                    elif dst_chain == 'sol':\n                        base_to_sol_count += 1\n\n        # 6. Decision Logic\n        if total_volume_moved == 0:\n            return \"NEUTRAL\", []\n            \n        if sol_to_base_count > base_to_sol_count:\n            return \"SOLANA_TO_BASE ğŸŒŠ\", self.monitored_wallets\n        elif base_to_sol_count > sol_to_base_count:\n            return \"BASE_TO_SOLANA ğŸŒŠ\", self.monitored_wallets\n            \n        return \"MIXED\", self.monitored_wallets\n\nprint(\"âœ… DeBridge Intelligence (Threshold > $2k) loaded.\")\n\n\n\n\n\n\n\n## -- End Cross Chain -- ##\n\n\n\n\n\n\n\n\n\n\n# --- 8. AGENTS ---\nclass SolanaScout:\n    def analyze(self, tx_log):\n        return ask_worker(\"Extract Token Name and Amount:\", tx_log)\n\nclass DeepReasoner:\n    def evaluate(self, token, context):\n        sys_prompt = (\n            \"You are a high-frequency trading algorithm. \"\n            \"Output ONLY one word: 'BUY' or 'PASS'.\"\n        )\n        return ask_brain(sys_prompt, f\"{context} Token: {token}\")\n\nprint(\"âœ… Engine Loaded (KNF, RugCheck, Cross-Chain, Fees).\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-02-22T08:26:57.931374Z","iopub.execute_input":"2026-02-22T08:26:57.932133Z","iopub.status.idle":"2026-02-22T08:26:57.982739Z","shell.execute_reply.started":"2026-02-22T08:26:57.932101Z","shell.execute_reply":"2026-02-22T08:26:57.982031Z"}},"outputs":[{"name":"stdout","text":"âœ… Cross-Chain Flow Detector loaded.\nâœ… Wormhole Scout loaded.\nâœ… DeBridge Intelligence (Threshold > $2k) loaded.\nâœ… Engine Loaded (KNF, RugCheck, Cross-Chain, Fees).\n","output_type":"stream"}],"execution_count":42},{"cell_type":"code","source":"# --- CELL 6: PAPER WALLET (PERSISTENT) ---\n\nimport json\n\nclass PaperWallet:\n    FILENAME = \"wallet_state.json\"\n\n    def __init__(self):\n        self.load_state()\n        if not hasattr(self, 'balances'):\n            self.balances = {\"SOL\": Config.INITIAL_BALANCE_SOL, \"ETH\": Config.INITIAL_BALANCE_ETH}\n\n    def save_state(self):\n        state = {\"balances\": self.balances}\n        with open(self.FILENAME, 'w') as f:\n            json.dump(state, f)\n\n    def load_state(self):\n        try:\n            with open(self.FILENAME, 'r') as f:\n                data = json.load(f)\n                self.balances = data['balances']\n                print(f\"   ğŸ’¾ Loaded Wallet State: {self.balances['SOL']:.2f} SOL\")\n        except:\n            print(\"   ğŸ†• Starting fresh wallet.\")\n\n    def buy(self, sym, addr, amt, price, chain=\"SOL\"):\n        curr = \"SOL\" if chain == \"SOL\" else \"ETH\"\n        if self.balances[curr] < amt: return False\n        self.balances[curr] -= amt\n        self.save_state()\n        print(f\"ğŸ’° BOUGHT {amt:.2f} {curr} of {sym} @ {price}\")\n        return True\n\n    def check_pnl(self):\n        \"\"\"Calculates PnL for all open positions in trade_log.json\"\"\"\n        logs = TradeLogger.get_open_positions()\n        if not logs:\n            print(\"   ğŸ“­ No open positions.\")\n            return\n\n        print(\"\\nğŸ“Š --- OPEN POSITIONS & PnL ---\")\n        total_pnl = 0\n        \n        for pos in logs:\n            sym = pos['symbol']\n            mint = pos['mint']\n            entry = pos['price']\n            tokens = pos['amount_tokens']\n            \n            # Fetch current price\n            curr_price_arr = DataService.get_token_history(mint, limit=10)\n            if len(curr_price_arr) > 0:\n                curr_price = curr_price_arr[-1]\n                curr_val = tokens * curr_price\n                entry_val = tokens * entry\n                pnl = curr_val - entry_val\n                pct = (pnl / entry_val) * 100\n                \n                status = \"ğŸ“ˆ\" if pnl > 0 else \"ğŸ“‰\"\n                print(f\"{status} {sym}: Entry ${entry:.6f} -> Now ${curr_price:.6f} | PnL: {pct:.2f}%\")\n                total_pnl += pnl\n            else:\n                print(f\"âš ï¸  {sym}: No price data.\")\n        \n        print(f\"------------------------------\\n   Total Unrealized PnL: ${total_pnl:.4f} USD\\n\")\n\n    def status(self):\n        \"\"\"Prints current wallet balances.\"\"\"\n        print(\"\\nğŸ’° WALLET BALANCES:\")\n        print(f\"   SOL: {self.balances['SOL']:.4f}\")\n        print(f\"   ETH: {self.balances['ETH']:.6f}\")\n\n# Initialize\npaper_wallet = PaperWallet()\nprint(\"âœ… Persistent Paper Wallet initialized. Run 6b Cell right after this\")\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-02-22T07:37:55.689207Z","iopub.execute_input":"2026-02-22T07:37:55.690503Z","iopub.status.idle":"2026-02-22T07:37:55.701296Z","shell.execute_reply.started":"2026-02-22T07:37:55.690471Z","shell.execute_reply":"2026-02-22T07:37:55.700636Z"}},"outputs":[{"name":"stdout","text":"   ğŸ†• Starting fresh wallet.\nâœ… Persistent Paper Wallet initialized. Run 6b Cell right after this\n","output_type":"stream"}],"execution_count":7},{"cell_type":"code","source":"# --- CELL 6b: UNIVERSAL MARKET SNAPSHOT (USDC + WSOL) ---\n\nimport json\nimport requests\nimport time\n\ndef fetch_market_snapshot():\n    print(\"ğŸ“¡ FETCHING UNIVERSAL SNAPSHOT (USDC + WSOL Pairs)...\")\n    \n    snapshot = {\n        \"timestamp\": time.time(),\n        \"solana\": [],\n        \"base\": []\n    }\n    \n    BASE_URL = \"https://api.dexscreener.com/latest/dex/search\"\n    \n    # STRATEGY: Search for BOTH USDC and WSOL to catch all major pairs\n    queries = {\n        \"solana\": [\n            \"EPjFWdd5AufqSSqeM2qN1xzybapC8G4wEGGkZwyTDt1v\", # Solana USDC\n            \"So11111111111111111111111111111111111111112\"  # Solana WSOL\n        ],\n        \"base\": [\n            \"0x833589fCD6eDb6E08f4c7C32D4f71b54bDA02913\",    # Base USDC\n            \"0x4200000000000000000000000000000000000006\"     # Base WETH (Common Base Pair)\n        ]\n    }\n    \n    for chain, address_list in queries.items():\n        print(f\"   Scanning {chain.upper()}...\")\n        \n        all_pairs = []\n        \n        for query in address_list:\n            params = {'q': query, 'limit': 50}\n            try:\n                r = requests.get(BASE_URL, params=params, timeout=15)\n                if r.status_code == 200:\n                    data = r.json()\n                    pairs = data.get('pairs', [])\n                    all_pairs.extend(pairs)\n            except Exception as e:\n                print(f\"   âš ï¸ Query {query} failed: {e}\")\n\n        # Filter & Deduplicate\n        seen_addresses = set()\n        filtered = []\n        \n        for p in all_pairs:\n            if p.get('chainId') == chain:\n                tvl = float(p.get('liquidity', {}).get('usd', 0))\n                vol = float(p.get('volume', {}).get('h24', 0))\n                token_addr = p.get('baseToken', {}).get('address')\n                \n                # Deduplicate by Token Address\n                if token_addr in seen_addresses or token_addr in address_list: continue\n                \n                if tvl > 20000 and vol > 5000:\n                    seen_addresses.add(token_addr)\n                    filtered.append(p)\n        \n        # Sort by Volume and take Top 20\n        filtered.sort(key=lambda x: float(x.get('volume', {}).get('h24', 0)), reverse=True)\n        top_20 = filtered[:50]\n        \n        # Normalize Data\n        for pool in top_20:\n            token = pool.get('baseToken', {})\n            quote = pool.get('quoteToken', {})\n            \n            # Determine the \"Target\" token (Not the quote currency we searched for)\n            # If we searched for USDC, and base is USDC, take Quote. Else take Base.\n            target = token\n            if token.get('address') in address_list:\n                target = quote\n            \n            # --- EXTRACT SOCIALS ---\n            # DexScreener returns a list of social links in 'info' -> 'socials'\n            socials = []\n            info = pool.get('info', {})\n            if 'socials' in info:\n                for social in info['socials']:\n                    if social.get('type') == 'twitter' or 'x.com' in social.get('url', ''):\n                        socials.append(social.get('url'))\n            \n            snapshot[chain].append({\n                \"symbol\": target.get('symbol'),\n                \"address\": target.get('address'),\n                \"name\": target.get('name'),\n                \"liquidity_usd\": float(pool.get('liquidity', {}).get('usd', 0)),\n                \"market_cap\": float(pool.get('marketCap', 0)),\n                \"volume_24h\": float(pool.get('volume', {}).get('h24', 0)),\n                \"socials\": socials # Store Twitter/X links here!\n            })\n                \n        print(f\"   âœ… Captured {len(top_20)} top pools for {chain.upper()}\")\n\n    # Save\n    with open(\"market_snapshot.json\", 'w') as f:\n        json.dump(snapshot, f, indent=2)\n    print(f\"\\nğŸ’¾ Snapshot saved. Total Tokens: {len(snapshot['solana']) + len(snapshot['base'])}\")\n\n# --- EXECUTE ---\nfetch_market_snapshot()\nprint(\"âœ… Run 6C Cell right after this\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-02-22T08:27:15.944884Z","iopub.execute_input":"2026-02-22T08:27:15.945474Z","iopub.status.idle":"2026-02-22T08:27:16.715357Z","shell.execute_reply.started":"2026-02-22T08:27:15.945445Z","shell.execute_reply":"2026-02-22T08:27:16.714650Z"}},"outputs":[{"name":"stdout","text":"ğŸ“¡ FETCHING UNIVERSAL SNAPSHOT (USDC + WSOL Pairs)...\n   Scanning SOLANA...\n   âœ… Captured 11 top pools for SOLANA\n   Scanning BASE...\n   âœ… Captured 3 top pools for BASE\n\nğŸ’¾ Snapshot saved. Total Tokens: 14\nâœ… Run 6C Cell right after this\n","output_type":"stream"}],"execution_count":43},{"cell_type":"code","source":"# --- CELL 6c: SOCIAL SENTIMENT ANALYZER (NITTER + VADER) ---\n\nimport requests\nfrom bs4 import BeautifulSoup\nfrom vaderSentiment.vaderSentiment import SentimentIntensityAnalyzer\n\nclass SocialSentimentService:\n    \"\"\"\n    Fetches tweets from Nitter and calculates sentiment using VADER.\n    \"\"\"\n    def __init__(self):\n        self.analyzer = SentimentIntensityAnalyzer()\n        self.headers = {'User-Agent': 'Mozilla/5.0'} \n\n    def get_token_sentiment(self, token_address, social_urls):\n        \"\"\"\n        Analyzes sentiment based on Nitter search results.\n        If no socials provided, or Nitter fails, returns NEUTRAL (0.0).\n        \"\"\"\n        if not social_urls:\n            # Fallback: Search by Address if no socials listed\n            search_url = f\"https://nitter.net/search?f=tweets&q={token_address}&since=&until=&min_faves=\"\n            print(f\"       ğŸ¦ Checking Nitter (Address Search)...\")\n            return self._fetch_and_analyze(search_url)\n        \n        # Use the primary Twitter link if available\n        primary_link = social_urls[0]\n        print(f\"       ğŸ¦ Checking Nitter (Social Link)...\")\n        return self._fetch_and_analyze(primary_link)\n\n    def _fetch_and_analyze(self, url):\n        try:\n            r = requests.get(url, headers=self.headers, timeout=10)\n            \n            if r.status_code == 200:\n                soup = BeautifulSoup(r.text, 'html.parser')\n                # Nitter usually puts tweets in divs with class 'tweet-content'\n                tweets = soup.find_all('div', class_='tweet-content')\n                \n                if not tweets:\n                    return 0.0 # Neutral if no tweets found\n                \n                # Analyze last 5 tweets\n                scores = []\n                for tweet in tweets[:5]:\n                    text = tweet.get_text()\n                    score = self.analyzer.polarity_scores(text)\n                    # 'compound' ranges from -1 (Negative) to 1 (Positive)\n                    scores.append(score['compound'])\n                \n                avg_score = sum(scores) / len(scores)\n                return avg_score\n            else:\n                # Nitter is often down/Rate limited\n                return 0.0 \n                \n        except Exception as e:\n            # Fail safe: Don't block trade if social check fails\n            # print(f\"       âš ï¸ Social Check Error: {e}\")\n            return 0.0\n\n# Initialize\nsocial_service = SocialSentimentService()\nprint(\"âœ… Social Sentiment Service loaded (Nitter + VADER). Run 6D afterwards.\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-02-22T08:27:42.765240Z","iopub.execute_input":"2026-02-22T08:27:42.766034Z","iopub.status.idle":"2026-02-22T08:27:42.786448Z","shell.execute_reply.started":"2026-02-22T08:27:42.766003Z","shell.execute_reply":"2026-02-22T08:27:42.785775Z"}},"outputs":[{"name":"stdout","text":"âœ… Social Sentiment Service loaded (Nitter + VADER). Run 6D afterwards.\n","output_type":"stream"}],"execution_count":44},{"cell_type":"code","source":"# --- CELL 6d: WHALE DISCOVERY (FIXED ENDPOINT) ---\n\nimport requests\nimport json\nfrom collections import Counter\nfrom datetime import datetime, timedelta\n\n# --- CONFIGURATION ---\n# The working endpoint for historical data\nAPI_URL = \"https://stats-api.dln.trade/api/Orders/filteredList\"\nWHALE_MIN_USD = 1000 \n# Expanded list of assets to watch (Whales usually move major pairs)\nWATCHED_ASSETS = [\"USDC\", \"USDT\", \"ETH\", \"WETH\", \"BTC\", \"WBTC\", \"SOLBTC\", \"SOL\"]\nOUTPUT_FILE = \"whales_24h.json\"\n\ndef discover_whales():\n    \"\"\"\n    Fetches bridge orders from the last 24-96 hours and filters for Whale behavior.\n    \"\"\"\n    print(\"ğŸ‹ STARTING WHALE DISCOVERY (Last 96h Window)...\")\n    \n    # Calculate timestamp for 4 days ago (4 days gives us more data to catch recent whales)\n    # Note: Use 96h (4 days) to be safe, filter strictly by time in logic.\n    time_threshold = int((datetime.now() - timedelta(hours=96)).timestamp())\n    \n    # Payload as defined in deBridge docs\n    payload = {\n        \"orderStates\": [\"Fulfilled\", \"SentUnlock\", \"ClaimedUnlock\"],\n        \"externalCallStates\": [\"NoExtCall\"], # Filter out complex smart contract calls\n        \"skip\": 0,\n        \"take\": 100  # Fetch a batch to analyze\n    }\n    \n    try:\n        # POST request to the stats API\n        response = requests.post(API_URL, json=payload, timeout=15)\n        \n        # Debug: Check status\n        if response.status_code != 200:\n            print(f\"   âš ï¸ API Error: {response.status_code} - {response.text}\")\n            return\n\n        data = response.json()\n        orders = data.get('items', [])\n        print(f\"   Fetched {len(orders)} total orders in time window.\")\n        \n        whale_log = []\n        wallet_volumes = Counter()\n\n        for order in orders:\n            # Extract Data\n            order_ts = order.get('creationTimestamp', 0)\n            usd_val = order.get('approximateUsdValue', 0)\n            maker = order.get('maker')\n            src_asset = order.get('giveAsset', {}).get('symbol', '').upper()\n            \n            # FILTER 1: Time (Last 96h)\n            if order_ts >= time_threshold:\n                \n                # FILTER 2: Value ($50,000+)\n                if usd_val >= WHALE_MIN_USD:\n                    \n                    # FILTER 3: Asset (Only major assets)\n                    if any(asset in src_asset for asset in WATCHED_ASSETS):\n                        \n                        whale_log.append({\n                            \"wallet\": maker,\n                            \"usd_value\": usd_val,\n                            \"asset\": src_asset,\n                            \"timestamp\": order_ts,\n                            \"tx_hash\": order.get('creationTxHash')\n                        })\n                        \n                        # Aggregate volume per wallet to find the BIGGEST whales\n                        wallet_volumes[maker] += usd_val\n\n        # Save Data to JSON\n        if whale_log:\n            save_whale_data(whale_log)\n            print_whale_leaderboard(wallet_volumes)\n        else:\n            print(\"   âš ï¸ No whale activity detected within criteria ($50k+ on tracked assets) in the last 96h.\")\n\n    except Exception as e:\n        print(f\"   âš ï¸ Script Error: {e}\")\n\ndef save_whale_data(entries):\n    with open(OUTPUT_FILE, 'w') as f:\n        json.dump(entries, f, indent=4)\n    print(f\"   âœ… Saved {len(entries)} whale moves to '{OUTPUT_FILE}'\")\n\ndef print_whale_leaderboard(volumes):\n    print(f\"\\nğŸ† --- TOP 10 WHALES (TOTAL VOLUME) --- ğŸ†\")\n    print(f\"{'Rank':<5} {'Wallet Address':<45} {'24h Volume':<20}\")\n    print(\"-\" * 75)\n    if not volumes:\n        print(\"   (No volume to display)\")\n    for i, (wallet, vol) in enumerate(volumes.most_common(10), 1):\n        # Truncate wallet for display\n        display_wallet = wallet[:6] + \"...\" + wallet[-4:]\n        print(f\"{i:<5} {display_wallet:<45} ${vol:,.2f}\")\n\n# --- EXECUTE ---\ndiscover_whales()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-02-22T08:27:51.284026Z","iopub.execute_input":"2026-02-22T08:27:51.284324Z","iopub.status.idle":"2026-02-22T08:27:58.764988Z","shell.execute_reply.started":"2026-02-22T08:27:51.284298Z","shell.execute_reply":"2026-02-22T08:27:58.764352Z"}},"outputs":[{"name":"stdout","text":"ğŸ‹ STARTING WHALE DISCOVERY (Last 96h Window)...\n   Fetched 0 total orders in time window.\n   âš ï¸ No whale activity detected within criteria ($50k+ on tracked assets) in the last 96h.\n","output_type":"stream"}],"execution_count":45},{"cell_type":"code","source":"# --- CELL 7: MARKET SCANNER (DEDUPLICATED) ---\n\nUSE_SIMULATED_RICH_WALLET = True \nSKIP_TOKENS = [\"USDC\", \"USDT\", \"PAI\", \"USDH\", \"TURBOS\"]\n\ndef run_market_scanner():\n    print(\"\\n\" + \"=\"*60)\n    print(\"ğŸš€ MAS V2: PORTFOLIO MANAGER\")\n    print(\"=\"*60)\n    \n    # 1. Initialize Tools\n    knf = AdvancedKNF()\n    reasoner = DeepReasoner()\n    \n    # 2. Check PnL\n    print(\"\\nğŸ“ˆ [1] CHECKING PORTFOLIO HEALTH...\")\n    paper_wallet.check_pnl()\n    \n    # 3. Scan\n    print(\"\\nğŸ” [2] SCANNING FOR NEW OPPORTUNITIES...\")\n    pools = MeteoraRecon.fetch_top_pools(limit=20) \n    \n    if not pools:\n        print(\"   âš ï¸ No pools found.\")\n        return\n\n    WSOL_MINT = \"So11111111111111111111111111111111111111112\"\n    seen_tokens = set() # Prevent analyzing the same token twice\n\n    for i, pool in enumerate(pools):\n        name = pool.get('name')\n        mint_x = pool.get('mint_x')\n        mint_y = pool.get('mint_y')\n        \n        # --- LOGIC: IDENTIFY TARGET ---\n        target_mint = None\n        target_name = name\n        \n        if mint_x == WSOL_MINT:\n            target_mint = mint_y\n            target_name = name.split('-')[-1].strip() \n        elif mint_y == WSOL_MINT:\n            target_mint = mint_x\n            target_name = name.split('-')[0].strip()\n        else:\n            continue \n\n        # --- OPTIMIZATION: SKIP DULPLICATES & STABLES ---\n        if target_name in SKIP_TOKENS or target_name in seen_tokens:\n            continue\n\n        seen_tokens.add(target_name) # Mark as analyzed\n\n        print(f\"\\n   [{i+1}] Analyzing: {target_name}...\")\n        \n        # --- FILTERS ---\n        tvl = float(pool.get('liquidity', 0))\n        if tvl < Config.MIN_TOKEN_TVL_USD:\n            print(f\"       âŒ TVL too low (${tvl:,.0f}).\")\n            continue\n            \n        # --- FORECAST ---\n        hist = DataService.get_token_history(target_mint, limit=100)\n        \n        if len(hist) > 0:\n            preds = knf.forecast(hist, steps=3)\n            \n            if len(preds) > 0 and preds[-1] > hist[-1]:\n                print(f\"       âœ… UPTREND (Next: {preds[-1]:.8f}).\")\n                \n                context = f\"Pool {name} (${tvl:,.0f}). KNF bullish.\"\n                decision = reasoner.evaluate(target_name, context)\n                \n                if \"BUY\" in decision.upper() or \"UP\" in decision.upper():\n                    paper_wallet.buy(target_name, target_mint, 10.0, hist[-1])\n                    TradeLogger.log_trade(target_name, target_mint, hist[-1], 10.0/hist[-1])\n                    print(f\"       ğŸ¤– AI: {decision[:60]}...\")\n                    print(f\"       ğŸ’° POSITION OPENED.\")\n                    break \n            else:\n                print(f\"       âŒ Trend is down/flat.\")\n        else:\n            print(f\"       âŒ No data.\")\n\n# --- EXECUTE ---\nrun_market_scanner()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-02-21T02:14:16.157868Z","iopub.execute_input":"2026-02-21T02:14:16.158927Z","iopub.status.idle":"2026-02-21T02:14:45.422387Z","shell.execute_reply.started":"2026-02-21T02:14:16.158888Z","shell.execute_reply":"2026-02-21T02:14:45.421519Z"}},"outputs":[{"name":"stdout","text":"\n============================================================\nğŸš€ MAS V2: PORTFOLIO MANAGER\n============================================================\n\nğŸ“ˆ [1] CHECKING PORTFOLIO HEALTH...\n\nğŸ“Š --- OPEN POSITIONS & PnL ---\nğŸ“‰ Punch: Entry $0.026730 -> Now $0.026205 | PnL: -1.96%\nğŸ“‰ Lobstar: Entry $0.008724 -> Now $0.008593 | PnL: -1.50%\nğŸ“‰ HYPE: Entry $30.739341 -> Now $30.505274 | PnL: -0.76%\nğŸ“‰ JUP: Entry $0.160873 -> Now $0.156111 | PnL: -2.96%\n------------------------------\n   Total Unrealized PnL: $-0.7189 USD\n\n\nğŸ” [2] SCANNING FOR NEW OPPORTUNITIES...\n\n   [4] Analyzing: Punch...\n       âŒ Trend is down/flat.\n\n   [6] Analyzing: Lobstar...\n       âŒ Trend is down/flat.\n\n   [8] Analyzing: cbBTC...\n       âœ… UPTREND (Next: 70373.67968750).\nğŸ’° BOUGHT 10.00 SOL of cbBTC @ 68433.20114247697\n   ğŸ“ Logged BUY: cbBTC\n       ğŸ¤– AI: Pool cbBTC-SOL ($2,583,026). KNF bullish. Token: cbBTC<think...\n       ğŸ’° POSITION OPENED.\n","output_type":"stream"}],"execution_count":16},{"cell_type":"code","source":"# --- CELL 7: AUTO-TRADER (WITH BRAND SAFETY) ---\n\nUSE_SIMULATED_RICH_WALLET = True \nSKIP_TOKENS = [\"USDC\", \"USDT\", \"PAI\", \"USDH\", \"TURBOS\"]\n\ndef run_market_scanner():\n    print(\"\\n\" + \"=\"*60)\n    print(\"ğŸš€ MAS V2: AUTO-TRADER (Brand Safety + SELL Logic)\")\n    print(\"=\"*60)\n    \n    # 1. Initialize Tools\n    knf = AdvancedKNF()\n    reasoner = DeepReasoner()\n    \n    # 2. PORTFOLIO MANAGEMENT\n    print(\"\\nğŸ“ˆ [1] CHECKING PORTFOLIO HEALTH & EXIT SIGNALS...\")\n    logs = TradeLogger.get_open_positions()\n    tokens_to_remove = []\n    \n    if logs:\n        for pos in logs:\n            sym = pos['symbol']\n            mint = pos['mint']\n            entry = pos['price']\n            \n            hist = DataService.get_token_history(mint, limit=100)\n            if len(hist) > 0:\n                curr = hist[-1]\n                pnl_pct = ((curr - entry) / entry) * 100\n                preds = knf.forecast(hist, steps=3)\n                \n                action = \"HOLD ğŸ¤²\"\n                \n                # EXIT LOGIC\n                if pnl_pct < -2.0 and len(preds) > 0 and preds[-1] < curr:\n                    action = \"SELL ğŸ›‘ (Stop Loss)\"\n                    tokens_to_remove.append(sym)\n                    TradeLogger.log_trade(sym, mint, curr, pos['amount_tokens'], action=\"SELL\")\n                    paper_wallet.balances[\"SOL\"] += (pos['amount_tokens'] * curr)\n                    print(f\"   ğŸ”´ {sym}: {pnl_pct:.2f}% | KNF Down -> EXITING.\")\n                elif pnl_pct > 10.0: # Increased profit target to 10%\n                    action = \"SELL ğŸ’° (Take Profit)\"\n                    tokens_to_remove.append(sym)\n                    TradeLogger.log_trade(sym, mint, curr, pos['amount_tokens'], action=\"SELL\")\n                    paper_wallet.balances[\"SOL\"] += (pos['amount_tokens'] * curr)\n                    print(f\"   ğŸŸ¢ {sym}: {pnl_pct:.2f}% | Target Hit -> EXITING.\")\n                else:\n                    status = \"ğŸ“ˆ\" if pnl_pct > 0 else \"ğŸ“‰\"\n                    print(f\"   {status} {sym}: {pnl_pct:.2f}% | KNF: {'Up' if preds[-1] > curr else 'Down'} -> {action}\")\n            else:\n                print(f\"   âš ï¸  {sym}: No data.\")\n    else:\n        print(\"   ğŸ“­ No open positions.\")\n\n    if tokens_to_remove:\n        print(f\"   ğŸ’° Closed positions: {', '.join(tokens_to_remove)}\")\n\n    # 3. SCAN FOR NEW BUYS\n    print(\"\\nğŸ” [2] SCANNING FOR NEW ENTRY SIGNALS...\")\n    pools = MeteoraRecon.fetch_top_pools(limit=20) \n    \n    if not pools: return\n\n    WSOL_MINT = \"So11111111111111111111111111111111111111112\"\n    seen_tokens = set()\n\n    for i, pool in enumerate(pools):\n        name = pool.get('name')\n        mint_x = pool.get('mint_x')\n        mint_y = pool.get('mint_y')\n        \n        # Identify Target\n        target_mint = None\n        target_name = name\n        \n        if mint_x == WSOL_MINT:\n            target_mint = mint_y\n            target_name = name.split('-')[-1].strip() \n        elif mint_y == WSOL_MINT:\n            target_mint = mint_x\n            target_name = name.split('-')[0].strip()\n        else:\n            continue \n\n        if target_name in SKIP_TOKENS or target_name in seen_tokens:\n            continue\n        seen_tokens.add(target_name)\n\n        if target_name in tokens_to_remove:\n            continue\n\n        print(f\"\\n   [{i+1}] Scanning: {target_name}...\")\n        \n        tvl = float(pool.get('liquidity', 0))\n        if tvl < Config.MIN_TOKEN_TVL_USD:\n            continue\n            \n        hist = DataService.get_token_history(target_mint, limit=100)\n        \n        if len(hist) > 0:\n            preds = knf.forecast(hist, steps=3)\n            \n            if len(preds) > 0 and preds[-1] > hist[-1]:\n                print(f\"       âœ… Technical: Uptrend Detected.\")\n                \n                # --- NEW: BRAND SAFETY CHECK ---\n                print(f\"       ğŸ›¡ï¸  Checking Brand Safety...\")\n                safety_prompt = (\n                    f\"Token Name: {target_name}. \"\n                    \"Is this a legitimate crypto project or meme? \"\n                    \"Ignore names like 'Scam', 'Rug', or 'Hack'. \"\n                    \"Answer 'SAFE' or 'UNSAFE'.\"\n                )\n                safety_verdict = ask_worker(\"Brand Safety Filter:\", safety_prompt)\n                \n                if \"UNSAFE\" in safety_verdict.upper():\n                    print(f\"       âŒ Brand Check Failed: {safety_verdict[:30]}\")\n                    continue\n                \n                print(f\"       âœ… Brand Check Passed.\")\n                \n                # --- DECISION ---\n                context = f\"Pool {name} (${tvl:,.0f}). KNF bullish. Brand Safe.\"\n                decision = reasoner.evaluate(target_name, context)\n                \n                if \"BUY\" in decision.upper():\n                    paper_wallet.buy(target_name, target_mint, 10.0, hist[-1])\n                    TradeLogger.log_trade(target_name, target_mint, hist[-1], 10.0/hist[-1])\n                    print(f\"       ğŸ¤– AI: {decision[:30]}...\")\n                    print(f\"       ğŸ’° POSITION OPENED.\")\n                    break \n            else:\n                print(f\"       âŒ No signal.\")\n        else:\n            continue\n\n# --- EXECUTE ---\nrun_market_scanner()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-02-21T02:44:56.713373Z","iopub.execute_input":"2026-02-21T02:44:56.714287Z","iopub.status.idle":"2026-02-21T02:45:23.135401Z","shell.execute_reply.started":"2026-02-21T02:44:56.714247Z","shell.execute_reply":"2026-02-21T02:45:23.134745Z"}},"outputs":[{"name":"stdout","text":"\n============================================================\nğŸš€ MAS V2: AUTO-TRADER (Brand Safety + SELL Logic)\n============================================================\n\nğŸ“ˆ [1] CHECKING PORTFOLIO HEALTH & EXIT SIGNALS...\n   ğŸ“­ No open positions.\n\nğŸ” [2] SCANNING FOR NEW ENTRY SIGNALS...\n\n   [4] Scanning: Punch...\n       âœ… Technical: Uptrend Detected.\n       ğŸ›¡ï¸  Checking Brand Safety...\n       âŒ Brand Check Failed: Analyzing the name \"Punch,\" I \n\n   [6] Scanning: Lobstar...\n       âŒ No signal.\n\n   [8] Scanning: cbBTC...\n       âŒ No signal.\n\n   [9] Scanning: HYPE...\n       âŒ No signal.\n\n   [10] Scanning: JUP...\n       âŒ No signal.\n\n   [11] Scanning: USELESS...\n       âŒ No signal.\n","output_type":"stream"}],"execution_count":38},{"cell_type":"code","source":"# --- CELL 7: UNIVERSAL SCANNER (WITH FEES & RULES) ---\n\nUSE_SIMULATED_RICH_WALLET = True \n\ndef run_universal_scanner():\n    print(\"\\n\" + \"=\"*60)\n    print(\"ğŸš€ MAS v3: UNIVERSAL SCANNER (Solana + Base)\")\n    print(\"=\"*60)\n    \n    # 1. Tools\n    knf = AdvancedKNF()\n    reasoner = DeepReasoner()\n    # --- NEW: Initialize RugCheck (No args needed, reads from Config) ---\n    rugcheck = RugCheckService()\n    \n    # 2. PORTFOLIO CHECK (Strict Rules)\n    print(\"\\nğŸ“ˆ [1] CHECKING PORTFOLIO (Strict SL/TP)...\")\n    logs = TradeLogger.get_open_positions()\n    tokens_to_remove = []\n    \n    if logs:\n        for pos in logs:\n            sym = pos['symbol']\n            chain = pos.get('chain', 'solana') # Assuming we stored this in log\n            mint = pos['mint']\n            entry = pos['price']\n            amt_tokens = pos['amount_tokens']\n            \n            # Get Current Price\n            hist = DataService.get_token_history(mint, limit=50)\n            if len(hist) == 0: continue\n            curr = hist[-1]\n            \n            # --- REAL PnL CALCULATION (Incl. Fees) ---\n            # Cost Basis = (Entry Price * Amount) + Buy Fees\n            buy_fee = FeeCalculator.estimate_buy_fees(chain, 0)\n            cost_basis = (entry * amt_tokens) + buy_fee\n            \n            # Exit Value = (Current Price * Amount) - Sell Fees\n            sell_fee = FeeCalculator.estimate_sell_fees(chain)\n            exit_value = (curr * amt_tokens) - sell_fee\n            \n            # Net PnL in USD (approx)\n            net_pnl = exit_value - cost_basis\n            net_pnl_pct = (net_pnl / cost_basis) * 100\n            \n            # --- RULES ---\n            action = \"HOLD\"\n            \n            # STOP LOSS: -5%\n            if net_pnl_pct <= -5.0:\n                action = \"SELL ğŸ›‘ (Stop Loss -5%)\"\n                tokens_to_remove.append(sym)\n                TradeLogger.log_trade(sym, mint, curr, amt_tokens, action=\"SELL\")\n                # Return net value to wallet\n                if chain == \"solana\":\n                    paper_wallet.balances[\"SOL\"] += exit_value\n                else:\n                    paper_wallet.balances[\"ETH\"] += exit_value\n                print(f\"   ğŸ”´ {sym} ({chain}): {net_pnl_pct:.2f}% -> {action}\")\n                \n            # TAKE PROFIT: +10%\n            elif net_pnl_pct >= 10.0:\n                action = \"SELL ğŸ’° (Take Profit +10%)\"\n                tokens_to_remove.append(sym)\n                TradeLogger.log_trade(sym, mint, curr, amt_tokens, action=\"SELL\")\n                if chain == \"solana\":\n                    paper_wallet.balances[\"SOL\"] += exit_value\n                else:\n                    paper_wallet.balances[\"ETH\"] += exit_value\n                print(f\"   ğŸŸ¢ {sym} ({chain}): {net_pnl_pct:.2f}% -> {action}\")\n            else:\n                print(f\"   ğŸ¤² {sym} ({chain}): {net_pnl_pct:.2f}% (Fee-Adjusted)\")\n\n    # 3. SCAN CHAINS (Dual Chain Loop)\n    print(\"\\nğŸ” [2] SCANNING CHAINS (Solana & Base)...\")\n    \n    chains = [\"solana\", \"base\"]\n    found_trade = False\n    \n    for chain in chains:\n        print(f\"\\n   --- Scanning {chain.upper()} ---\")\n        pools = CrossChainRecon.get_top_pools(chain_id=chain, limit=5)\n        \n        for i, pool in enumerate(pools):\n            if found_trade: break # Stop if we found a trade\n\n            name = pool.get('baseToken', {}).get('symbol')\n            mint = pool.get('baseToken', {}).get('address')\n            # DexScreener gives price directly\n            price = float(pool.get('priceUsd', 0))\n            tvl = pool.get('liquidity', {}).get('usd', 0)\n            \n            print(f\"   [{i+1}] {name} (${price:.6f})...\")\n            \n            # Check liquidity\n            if tvl < Config.MIN_TOKEN_TVL_USD:\n                print(f\"       âŒ TVL Low.\")\n                continue\n            \n            # Forecast\n            hist = DataService.get_token_history(mint, limit=100)\n            if len(hist) > 0:\n                preds = knf.forecast(hist, steps=3)\n                \n                if len(preds) > 0 and preds[-1] > hist[-1]:\n                    print(f\"       âœ… Trend UP.\")\n                    \n                    # RugCheck (Solana Only)\n                    safe = True\n                    if chain == \"solana\":\n                        safety = rugcheck.verify_token(mint)\n                        print(f\"       ğŸ›¡ï¸  Safety: {safety['msg'][:50]}...\")\n                        if not safety['safe']: continue\n                    else:\n                        print(f\"       ğŸ›¡ï¸  Safety: Base Chain (No RugCheck API).\")\n\n                    # AI Decision\n                    context = f\"{chain.upper()} {name}. TVL ${tvl:,.0f}. Trend UP.\"\n                    decision = reasoner.evaluate(name, context)\n                    \n                    if \"BUY\" in decision.upper():\n                        # EXECUTE PAPER BUY (With Fees)\n                        investment = 10.0 # Spend 10 native units\n                        fee = FeeCalculator.estimate_buy_fees(chain, investment)\n                        net_invest = investment - fee\n                        \n                        amount_tokens = net_invest / price\n                        \n                        # Log\n                        trade_chain = \"SOL\" if chain == \"solana\" else \"ETH\"\n                        paper_wallet.balances[trade_chain] -= investment\n                        TradeLogger.log_trade(name, mint, price, amount_tokens, action=\"BUY\", chain=chain)\n                        \n                        print(f\"       ğŸ¤– AI: BUY\")\n                        print(f\"       ğŸ’° BOUGHT {amount_tokens:.2f} {name} @ ${price}\")\n                        print(f\"       ğŸ’¸ Fee Paid: {fee:.6f} {trade_chain}\")\n                        found_trade = True\n                        break\n                else:\n                    print(f\"       âŒ Trend Down.\")\n    \n    paper_wallet.status()\n\n# --- EXECUTE ---\nrun_universal_scanner()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-02-21T20:21:21.610170Z","iopub.execute_input":"2026-02-21T20:21:21.610782Z","iopub.status.idle":"2026-02-21T20:21:28.211699Z","shell.execute_reply.started":"2026-02-21T20:21:21.610736Z","shell.execute_reply":"2026-02-21T20:21:28.211089Z"}},"outputs":[{"name":"stdout","text":"\n============================================================\nğŸš€ MAS v3: UNIVERSAL SCANNER (Solana + Base)\n============================================================\n\nğŸ“ˆ [1] CHECKING PORTFOLIO (Strict SL/TP)...\n\nğŸ” [2] SCANNING CHAINS (Solana & Base)...\n\n   --- Scanning SOLANA ---\n   [1] memecoin ($0.000354)...\n       âŒ Trend Down.\n   [2] Oil ($0.000271)...\n       âŒ Trend Down.\n\n   --- Scanning BASE ---\n   [1] TN100x ($0.000027)...\n       âŒ Trend Down.\n\nğŸ’° WALLET BALANCES:\n   SOL: 100.0000\n   ETH: 1.000000\n","output_type":"stream"}],"execution_count":24},{"cell_type":"code","source":"# --- CELL 7: UNIVERSAL SCANNER (WITH FORMATTED PORTFOLIO) ---\n\nimport json \n\nUSE_SIMULATED_RICH_WALLET = True \n\ndef run_universal_scanner():\n    print(\"\\n\" + \"=\"*60)\n    print(\"ğŸš€ MAS v3: SNAPSHOT ANALYZER (Solana + Base + Social)\")\n    print(\"=\"*60)\n    \n    # 1. Tools\n    knf = AdvancedKNF()\n    reasoner = DeepReasoner()\n    rugcheck = RugCheckService()\n    \n    # Ensure Social Service is loaded\n    if 'social_service' in globals():\n        social_service = globals()['social_service']\n    else:\n        social_service = None\n    \n    # 2. LOAD SNAPSHOT DATA\n    try:\n        with open(\"market_snapshot.json\", 'r') as f:\n            snapshot = json.load(f)\n        print(\"ğŸ“‚ Market Snapshot Loaded.\")\n    except FileNotFoundError:\n        print(\"âŒ 'market_snapshot.json' not found.\")\n        print(\"âš ï¸  Please run Cell 6b (Market Snapshot) first.\")\n        return\n    \n    # 3. PORTFOLIO CHECK (Strict Rules & Formatted Output)\n    print(\"\\nğŸ“ˆ [1] CHECKING PORTFOLIO HEALTH...\")\n    \n    logs = TradeLogger.get_open_positions()\n    \n    # List to store display data for the table\n    portfolio_display = []\n    total_unrealized_pnl = 0.0\n    \n    if logs:\n        for pos in logs:\n            sym = pos['symbol']\n            chain = pos.get('chain', 'solana') \n            mint = pos['mint']\n            entry = pos['price']\n            amt_tokens = pos['amount_tokens']\n            \n            # Get Current Price\n            hist = DataService.get_token_history(mint, limit=50)\n            if len(hist) == 0: continue\n            curr = hist[-1]\n            \n            # --- REAL PnL CALCULATION (Incl. Fees) ---\n            buy_fee = FeeCalculator.estimate_buy_fees(chain, 0)\n            cost_basis = (entry * amt_tokens) + buy_fee\n            sell_fee = FeeCalculator.estimate_sell_fees(chain)\n            exit_value = (curr * amt_tokens) - sell_fee\n            \n            net_pnl = exit_value - cost_basis\n            net_pnl_pct = (net_pnl / cost_basis) * 100\n            \n            # --- RULES ---\n            action = \"HOLD\"\n            \n            # STOP LOSS: -5%\n            if net_pnl_pct <= -5.0:\n                action = \"SELL ğŸ›‘ (Stop Loss -5%)\"\n                TradeLogger.log_trade(sym, mint, curr, amt_tokens, action=\"SELL\")\n                if chain == \"solana\":\n                    paper_wallet.balances[\"SOL\"] += exit_value\n                else:\n                    paper_wallet.balances[\"ETH\"] += exit_value\n                \n            # TAKE PROFIT: +10%\n            elif net_pnl_pct >= 10.0:\n                action = \"SELL ğŸ’° (Take Profit +10%)\"\n                TradeLogger.log_trade(sym, mint, curr, amt_tokens, action=\"SELL\")\n                if chain == \"solana\":\n                    paper_wallet.balances[\"SOL\"] += exit_value\n                else:\n                    paper_wallet.balances[\"ETH\"] += exit_value\n            else:\n                # Add to display list if holding\n                total_unrealized_pnl += net_pnl\n                icon = \"ğŸ“ˆ\" if net_pnl > 0 else \"ğŸ“‰\"\n                portfolio_display.append({\n                    \"icon\": icon,\n                    \"sym\": sym,\n                    \"entry\": entry,\n                    \"curr\": curr,\n                    \"pnl\": net_pnl_pct\n                })\n\n    # --- PRINT THE TABLE ---\n    print(\"ğŸ“Š --- OPEN POSITIONS & PnL ---\")\n    if portfolio_display:\n        for item in portfolio_display:\n            print(f\"{item['icon']} {item['sym']}: Entry ${item['entry']:.6f} -> Now ${item['curr']:.6f} | PnL: {item['pnl']:.2f}%\")\n    else:\n        print(\"   ğŸ“­ No open positions.\")\n\n    print(f\"------------------------------\\n   Total Unrealized PnL: ${total_unrealized_pnl:.4f} USD\\n\")\n\n\n    # 4. ANALYZE SNAPSHOT\n    print(\"\\nğŸ” [2] ANALYZING SNAPSHOT DATA...\")\n    \n    found_trade = False\n    \n    for chain_key, tokens in snapshot.items():\n        if not isinstance(tokens, list): continue\n            \n        print(f\"\\n   --- Analyzing {chain_key.upper()} ---\")\n        \n        for token_data in tokens:\n            if found_trade: break \n\n            sym = token_data['symbol']\n            mint = token_data['address']\n            tvl = token_data['liquidity_usd']\n            mcap = token_data['market_cap']\n            \n            # --- FILTER: SKIP STABLECOINS ---\n            if sym in [\"USDC\", \"USDT\", \"USDD\", \"DAI\", \"WETH\", \"WSOL\"]:\n                continue\n\n            # Fetch LIVE price\n            hist = DataService.get_token_history(mint, limit=100)\n            if len(hist) == 0: continue\n            price = hist[-1]\n            \n            print(f\"   [{tokens.index(token_data)+1}] {sym} | TVL: ${tvl:,.0f} | MCap: ${mcap:,.0f}...\")\n            \n            if tvl < Config.MIN_TOKEN_TVL_USD:\n                print(f\"       âŒ TVL Low.\")\n                continue\n            \n            # Forecast\n            preds = knf.forecast(hist, steps=3)\n            \n            if len(preds) > 0 and preds[-1] > hist[-1]:\n                print(f\"       âœ… Trend UP.\")\n                \n                # RugCheck (Solana Only)\n                safe = True\n                if chain_key == \"solana\":\n                    safety = rugcheck.verify_token(mint)\n                    print(f\"       ğŸ›¡ï¸  {safety['msg'][:50]}...\")\n                    if not safety['safe']: continue\n                else:\n                    print(f\"       ğŸ›¡ï¸  Base Chain (Skip RugCheck).\")\n\n                # --- SOCIAL SENTIMENT CHECK ---\n                sentiment_score = 0.0\n                sentiment_label = \"Neutral\"\n                \n                if social_service:\n                    socials = token_data.get('socials', [])\n                    sentiment_score = social_service.get_token_sentiment(mint, socials)\n                    \n                    if sentiment_score > 0.05: sentiment_label = \"Bullish ğŸ‚\"\n                    elif sentiment_score < -0.05: sentiment_label = \"Bearish ğŸ»\"\n                else:\n                    sentiment_label = \"No Data\"\n\n                print(f\"       ğŸ’¬ Social Sentiment: {sentiment_label} ({sentiment_score:.2f})\")\n                \n                # Filter: Toxic Sentiment\n                if sentiment_score < -0.5:\n                    print(f\"       âŒ REJECTED: Community sentiment is toxic.\")\n                    continue\n\n                # AI Decision\n                context = f\"{chain_key.upper()} {sym}. TVL ${tvl:,.0f}. MCap ${mcap:,.0f}. Trend UP. Sentiment: {sentiment_label}.\"\n                decision = reasoner.evaluate(sym, context)\n                \n                if \"BUY\" in decision.upper():\n                    # --- SMART INVESTMENT ---\n                    investment = 0.1 if chain_key == \"base\" else 10.0\n                    \n                    # --- USE THE WALLET METHOD (Checks Balance) ---\n                    success = paper_wallet.buy(sym, mint, investment, price, chain=chain_key)\n                    \n                    if success:\n                        fee = FeeCalculator.estimate_buy_fees(chain_key, investment)\n                        net_invest = investment - fee\n                        amount_tokens = net_invest / price\n                        \n                        # Log (Don't double deduct balance!)\n                        TradeLogger.log_trade(sym, mint, price, amount_tokens, action=\"BUY\", chain=chain_key)\n                        \n                        print(f\"       ğŸ¤– AI: BUY\")\n                        print(f\"       ğŸ’° BOUGHT {amount_tokens:.2f} {sym} @ ${price}\")\n                        print(f\"       ğŸ’¸ Fee: {fee:.6f}\")\n                        found_trade = True\n                        break\n            else:\n                print(f\"       âŒ Trend Down.\")\n    \n    paper_wallet.status()\n\n# --- EXECUTE ---\nrun_universal_scanner()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-02-21T22:45:47.208324Z","iopub.execute_input":"2026-02-21T22:45:47.209122Z","iopub.status.idle":"2026-02-21T22:46:52.670065Z","shell.execute_reply.started":"2026-02-21T22:45:47.209091Z","shell.execute_reply":"2026-02-21T22:46:52.669149Z"}},"outputs":[{"name":"stdout","text":"\n============================================================\nğŸš€ MAS v3: SNAPSHOT ANALYZER (Solana + Base + Social)\n============================================================\nğŸ“‚ Market Snapshot Loaded.\n\nğŸ“ˆ [1] CHECKING PORTFOLIO HEALTH...\n   ğŸ“ Logged SELL: OWB\nğŸ“Š --- OPEN POSITIONS & PnL ---\nğŸ“‰ OWB: Entry $0.080103 -> Now $0.077487 | PnL: -3.46%\nğŸ“ˆ ZORA: Entry $0.019980 -> Now $0.020685 | PnL: 3.33%\nğŸ“‰ ZORA: Entry $0.020293 -> Now $0.020192 | PnL: -0.70%\nğŸ“‰ AERO: Entry $0.325455 -> Now $0.325005 | PnL: -0.34%\nğŸ“‰ SOL: Entry $87.200015 -> Now $85.796409 | PnL: -1.81%\nğŸ“‰ OWB: Entry $0.079713 -> Now $0.078558 | PnL: -1.65%\nğŸ“ˆ OWB: Entry $0.079613 -> Now $0.083704 | PnL: 4.93%\nğŸ“ˆ AERO: Entry $0.321966 -> Now $0.336341 | PnL: 4.26%\nğŸ“ˆ cbBTC: Entry $66129.915427 -> Now $68112.063580 | PnL: 2.79%\nğŸ“ˆ cbBTC: Entry $69537.855116 -> Now $69883.445781 | PnL: 0.30%\nğŸ“ˆ AERO: Entry $0.324759 -> Now $0.332765 | PnL: 2.26%\nğŸ“ˆ ZORA: Entry $0.019965 -> Now $0.020740 | PnL: 3.68%\nğŸ“ˆ SOL: Entry $84.160825 -> Now $86.281398 | PnL: 2.32%\nğŸ“ˆ AERO: Entry $0.318942 -> Now $0.339133 | PnL: 6.12%\n------------------------------\n   Total Unrealized PnL: $0.0220 USD\n\n\nğŸ” [2] ANALYZING SNAPSHOT DATA...\n\n   --- Analyzing SOLANA ---\n   [1] TRUMP | TVL: $28,806,714 | MCap: $807,756,270...\n       âŒ Trend Down.\n   [2] 9bit | TVL: $862,137 | MCap: $169,213,214...\n       âŒ Trend Down.\n   [3] XMN | TVL: $322,693 | MCap: $14,009,836...\n       âŒ Trend Down.\n   [4] PUMP | TVL: $14,603,935 | MCap: $1,244,796,581...\n       âŒ Trend Down.\n   [5] BIRB | TVL: $1,778,237 | MCap: $49,160,242...\n       âŒ Trend Down.\n   [6] SKR | TVL: $614,747 | MCap: $110,291,238...\n       âŒ Trend Down.\n   [7] AVICI | TVL: $803,189 | MCap: $14,042,945...\n       âŒ Trend Down.\n   [8] UMBRA | TVL: $1,805,703 | MCap: $10,164,495...\n       âŒ Trend Down.\n   [9] URANUS | TVL: $173,910 | MCap: $1,653,049...\n       âŒ Trend Down.\n\n   --- Analyzing BASE ---\n   [1] cbBTC | TVL: $2,424,484 | MCap: $2,125,946,895...\n       âœ… Trend UP.\n       ğŸ›¡ï¸  Base Chain (Skip RugCheck).\n       ğŸ¦ Checking Nitter (Address Search)...\n       ğŸ’¬ Social Sentiment: Neutral (0.00)\nğŸ’° BOUGHT 0.10 ETH of cbBTC @ 68208.1716333298\n   ğŸ“ Logged BUY: cbBTC\n       ğŸ¤– AI: BUY\n       ğŸ’° BOUGHT 0.00 cbBTC @ $68208.1716333298\n       ğŸ’¸ Fee: 0.000100\n\nğŸ’° WALLET BALANCES:\n   SOL: 100.0000\n   ETH: 0.250098\n","output_type":"stream"}],"execution_count":143},{"cell_type":"code","source":"# --- CELL 7: MASTER UNIVERSAL SCANNER (FIXED INITIALIZATION) ---\n\nimport json \nimport time\n\nUSE_SIMULATED_RICH_WALLET = True \n\ndef run_universal_scanner():\n    print(\"\\n\" + \"=\"*60)\n    print(\"ğŸš€ MAS v3: MASTER SCANNER (Whale Rotation + Sentiment)\")\n    print(\"=\"*60)\n    \n    # 1. TOOLS INITIALIZATION\n    knf = AdvancedKNF()\n    reasoner = DeepReasoner()\n    rugcheck = RugCheckService()\n    \n    # Load Modules (Instantiate where necessary)\n    social_service = globals().get('social_service')\n    \n    # FIX: Instantiate the DeBridge Intelligence class\n    if 'DeBridgeIntelligence' in globals():\n        debridge_service = DeBridgeIntelligence() \n    else:\n        print(\"âš ï¸  DeBridge Intelligence class not found. Ensure Cell 5 was run.\")\n        debridge_service = None\n    \n    # 2. LOAD MARKET SNAPSHOT\n    try:\n        with open(\"market_snapshot.json\", 'r') as f:\n            snapshot = json.load(f)\n        print(\"ğŸ“‚ Market Snapshot Loaded.\")\n    except FileNotFoundError:\n        print(\"âŒ 'market_snapshot.json' not found. Run Cell 6b first.\")\n        return\n    \n    # 3. PORTFOLIO HEALTH CHECK\n    print(\"\\nğŸ“ˆ [1] CHECKING PORTFOLIO HEALTH...\")\n    \n    logs = TradeLogger.get_open_positions()\n    portfolio_display = []\n    total_unrealized_pnl = 0.0\n    \n    if logs:\n        for pos in logs:\n            sym = pos['symbol']\n            chain = pos.get('chain', 'solana') \n            mint = pos['mint']\n            entry = pos['price']\n            amt_tokens = pos['amount_tokens']\n            \n            hist = DataService.get_token_history(mint, limit=50)\n            if len(hist) == 0: continue\n            curr = hist[-1]\n            \n            buy_fee = FeeCalculator.estimate_buy_fees(chain, 0)\n            cost_basis = (entry * amt_tokens) + buy_fee\n            sell_fee = FeeCalculator.estimate_sell_fees(chain)\n            exit_value = (curr * amt_tokens) - sell_fee\n            \n            net_pnl = exit_value - cost_basis\n            net_pnl_pct = (net_pnl / cost_basis) * 100\n            \n            action = \"HOLD\"\n            \n            if net_pnl_pct <= -5.0:\n                action = \"SELL ğŸ›‘ (Stop Loss)\"\n                TradeLogger.log_trade(sym, mint, curr, amt_tokens, action=\"SELL\")\n                if chain == \"solana\":\n                    paper_wallet.balances[\"SOL\"] += exit_value\n                else:\n                    paper_wallet.balances[\"ETH\"] += exit_value\n            elif net_pnl_pct >= 10.0:\n                action = \"SELL ğŸ’° (Take Profit)\"\n                TradeLogger.log_trade(sym, mint, curr, amt_tokens, action=\"SELL\")\n                if chain == \"solana\":\n                    paper_wallet.balances[\"SOL\"] += exit_value\n                else:\n                    paper_wallet.balances[\"ETH\"] += exit_value\n            else:\n                total_unrealized_pnl += net_pnl\n                icon = \"ğŸ“ˆ\" if net_pnl > 0 else \"ğŸ“‰\"\n                portfolio_display.append({\n                    \"icon\": icon,\n                    \"sym\": sym,\n                    \"entry\": entry,\n                    \"curr\": curr,\n                    \"pnl\": net_pnl_pct\n                })\n\n    print(\"ğŸ“Š --- OPEN POSITIONS & PnL ---\")\n    if portfolio_display:\n        for item in portfolio_display:\n            print(f\"{item['icon']} {item['sym']}: Entry ${item['entry']:.6f} -> Now ${item['curr']:.6f} | PnL: {item['pnl']:.2f}%\")\n    else:\n        print(\"   ğŸ“­ No open positions.\")\n    print(f\"------------------------------\\n   Total Unrealized PnL: ${total_unrealized_pnl:.4f} USD\\n\")\n\n    # 4. SECTOR ROTATION (DEBRIDGE INTELLIGENCE)\n    print(\"\\nğŸŒ‰ [2] DEBRIDGE INTELLIGENCE: TRACKING WHALES (>$2k THRESHOLD)...\")\n    \n    scan_order = [\"solana\", \"base\"]\n    \n    if debridge_service:\n        flow_direction, active_wallets = debridge_service.detect_rotation_signals()\n        \n        print(f\"   Flow Direction: {flow_direction}\")\n        print(f\"   Active Wallets Monitored: {len(active_wallets)}\")\n        \n        if flow_direction == \"SOLANA_TO_BASE ğŸŒŠ\":\n            print(\"   ğŸ’¡ STRATEGY: Capital rotating OUT of Solana -> BASE.\")\n            scan_order = [\"base\", \"solana\"]\n        elif flow_direction == \"BASE_TO_SOLANA ğŸŒŠ\":\n            print(\"   ğŸ’¡ STRATEGY: Capital rotating OUT of BASE -> SOLANA.\")\n            scan_order = [\"solana\", \"base\"]\n        else:\n            print(\"   ğŸ’¡ Observation: No significant bridge activity detected.\")\n    else:\n        print(\"   âš ï¸  DeBridge Intelligence not initialized. Scanning normally.\")\n\n    # 5. ANALYZE SNAPSHOT\n    print(\"\\nğŸ” [3] ANALYZING SNAPSHOT DATA...\")\n    \n    found_trade = False\n    \n    for chain_key in scan_order:\n        if chain_key not in snapshot: continue\n        if not isinstance(snapshot[chain_key], list): continue\n            \n        print(f\"\\n   --- Analyzing {chain_key.upper()} ---\")\n        tokens = snapshot[chain_key]\n        \n        for token_data in tokens:\n            if found_trade: break \n\n            sym = token_data['symbol']\n            mint = token_data['address']\n            tvl = token_data['liquidity_usd']\n            mcap = token_data['market_cap']\n            \n            if sym in [\"USDC\", \"USDT\", \"USDD\", \"DAI\", \"WETH\", \"WSOL\", \"CBETH\", \"ZRO\"]:\n                continue\n\n            hist = DataService.get_token_history(mint, limit=100)\n            if len(hist) == 0: continue\n            price = hist[-1]\n            \n            print(f\"   [{tokens.index(token_data)+1}] {sym} | TVL: ${tvl:,.0f} | MCap: ${mcap:,.0f}...\")\n            \n            if tvl < Config.MIN_TOKEN_TVL_USD:\n                print(f\"       âŒ TVL Low.\")\n                continue\n            \n            preds = knf.forecast(hist, steps=3)\n            \n            if len(preds) > 0 and preds[-1] > hist[-1]:\n                print(f\"       âœ… Trend UP.\")\n                \n                safe = True\n                if chain_key == \"solana\":\n                    safety = rugcheck.verify_token(mint)\n                    print(f\"       ğŸ›¡ï¸  {safety['msg'][:50]}...\")\n                    if not safety['safe']: continue\n                else:\n                    print(f\"       ğŸ›¡ï¸  Base Chain (Skip RugCheck).\")\n\n                sentiment_score = 0.0\n                sentiment_label = \"Neutral\"\n                \n                if social_service:\n                    socials = token_data.get('socials', [])\n                    sentiment_score = social_service.get_token_sentiment(mint, socials)\n                    \n                    if sentiment_score > 0.05: sentiment_label = \"Bullish ğŸ‚\"\n                    elif sentiment_score < -0.05: sentiment_label = \"Bearish ğŸ»\"\n                else:\n                    sentiment_label = \"No Data\"\n\n                print(f\"       ğŸ’¬ Social Sentiment: {sentiment_label} ({sentiment_score:.2f})\")\n                \n                if sentiment_score < -0.5:\n                    print(f\"       âŒ REJECTED: Community sentiment is toxic.\")\n                    continue\n\n                context = f\"{chain_key.upper()} {sym}. TVL ${tvl:,.0f}. MCap ${mcap:,.0f}. Trend UP. Sentiment: {sentiment_label}.\"\n                decision = reasoner.evaluate(sym, context)\n                \n                if \"BUY\" in decision.upper():\n                    investment = 0.1 if chain_key == \"base\" else 10.0\n                    success = paper_wallet.buy(sym, mint, investment, price, chain=chain_key)\n                    \n                    if success:\n                        fee = FeeCalculator.estimate_buy_fees(chain_key, investment)\n                        net_invest = investment - fee\n                        amount_tokens = net_invest / price\n                        \n                        TradeLogger.log_trade(sym, mint, price, amount_tokens, action=\"BUY\", chain=chain_key)\n                        \n                        print(f\"       ğŸ¤– AI: BUY\")\n                        print(f\"       ğŸ’° BOUGHT {amount_tokens:.2f} {sym} @ ${price}\")\n                        print(f\"       ğŸ’¸ Fee: {fee:.6f}\")\n                        found_trade = True\n                        break\n            else:\n                print(f\"       âŒ Trend Down.\")\n    \n    paper_wallet.status()\n\n# --- EXECUTE ---\nrun_universal_scanner()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-02-22T07:01:20.502431Z","iopub.execute_input":"2026-02-22T07:01:20.503002Z","iopub.status.idle":"2026-02-22T07:01:47.355742Z","shell.execute_reply.started":"2026-02-22T07:01:20.502971Z","shell.execute_reply":"2026-02-22T07:01:47.354955Z"}},"outputs":[{"name":"stdout","text":"\n============================================================\nğŸš€ MAS v3: MASTER SCANNER (Whale Rotation + Sentiment)\n============================================================\n   ğŸ“‚ Loaded 0 active whale wallets from whales_24h.json\nğŸ“‚ Market Snapshot Loaded.\n\nğŸ“ˆ [1] CHECKING PORTFOLIO HEALTH...\nğŸ“Š --- OPEN POSITIONS & PnL ---\nğŸ“ˆ AERO: Entry $0.324052 -> Now $0.331664 | PnL: 2.15%\nğŸ“ˆ AERO: Entry $0.317158 -> Now $0.326410 | PnL: 2.71%\n------------------------------\n   Total Unrealized PnL: $0.0049 USD\n\n\nğŸŒ‰ [2] DEBRIDGE INTELLIGENCE: TRACKING WHALES (>$2k THRESHOLD)...\n   ğŸ‹ Scanning DeBridge for High-Value Transfers (>$2,000 USD)...\n   Flow Direction: NEUTRAL\n   Active Wallets Monitored: 0\n   ğŸ’¡ Observation: No significant bridge activity detected.\n\nğŸ” [3] ANALYZING SNAPSHOT DATA...\n\n   --- Analyzing SOLANA ---\n   [1] TRUMP | TVL: $28,237,410 | MCap: $790,975,804...\n       âŒ Trend Down.\n   [2] 9bit | TVL: $868,835 | MCap: $177,031,426...\n       âœ… Trend UP.\n       ğŸ›¡ï¸  âŒ BLOCK: Mint Authority Active, Freeze Authority A...\n   [3] PUMP | TVL: $14,537,126 | MCap: $1,233,343,901...\n       âŒ Trend Down.\n   [4] XMN | TVL: $315,434 | MCap: $13,393,910...\n       âŒ Trend Down.\n   [5] KMNO | TVL: $1,638,945 | MCap: $109,349,456...\n       âŒ Trend Down.\n   [6] BIRB | TVL: $1,769,051 | MCap: $47,755,644...\n       âŒ Trend Down.\n   [7] SKR | TVL: $609,290 | MCap: $108,511,552...\n       âŒ Trend Down.\n   [8] CARDS | TVL: $845,295 | MCap: $11,311,813...\n       âŒ Trend Down.\n   [9] AVICI | TVL: $804,366 | MCap: $14,072,419...\n       âŒ Trend Down.\n   [10] UMBRA | TVL: $1,810,817 | MCap: $10,202,947...\n       âŒ Trend Down.\n   [11] URANUS | TVL: $169,644 | MCap: $1,572,921...\n       âŒ Trend Down.\n\n   --- Analyzing BASE ---\n   [1] cbBTC | TVL: $2,429,123 | MCap: $2,124,040,810...\n       âŒ Trend Down.\n   [2] AERO | TVL: $19,708,556 | MCap: $296,974,233...\n       âŒ Trend Down.\n\nğŸ’° WALLET BALANCES:\n   SOL: 100.0000\n   ETH: 0.894738\n","output_type":"stream"}],"execution_count":47},{"cell_type":"code","source":"# --- CELL 7: MASTER UNIVERSAL SCANNER (ROBUST FIX) ---\n\nimport json \nimport time\nimport requests\n\nUSE_SIMULATED_RAGGED_WALLET = True \n\ndef run_universal_scanner():\n    print(\"\\n\" + \"=\"*60)\n    print(\"ğŸš€ MAS v3: MASTER SCANNER (Rotation + Sentiment + Bridge Quality)\")\n    print(\"=\"*60)\n    \n    # 1. TOOLS INITIALIZATION\n    knf = AdvancedKNF()\n    reasoner = DeepReasoner()\n    rugcheck = RugCheckService()\n    \n    # Load Modules\n    social_service = globals().get('social_service')\n    \n    # Instantiate DeBridge Intelligence\n    if 'DeBridgeIntelligence' in globals():\n        debridge_service = DeBridgeIntelligence() \n    else:\n        print(\"âš ï¸ 1ï¸âƒ£ï¸ Cell 5 (DeBridge) not run.\")\n        debridge_service = None\n        \n    # Instantiate Wormhole Scout\n    if 'WormholeScout' in globals():\n        wormhole_service = WormholeScout()\n    else:\n        print(\"âš ï¸ 2ï¸âƒ£ï¸ Cell 5 (Wormhole) not run.\")\n        wormhole_service = None\n    \n    # 2. LOAD MARKET SNAPSHOT\n    try:\n        with open(\"market_snapshot.json\", 'r') as f:\n            snapshot = json.load(f)\n        print(\"ğŸ“‚ Market Snapshot Loaded.\")\n    except FileNotFoundError:\n        print(\"âŒ 'market_snapshot.json' not found. Run Cell 6b first.\")\n        return\n    \n    # 3. PORTFOLIO HEALTH CHECK\n    print(\"\\nğŸ“ˆ [1] CHECKING PORTFOLIO HEALTH...\")\n    \n    logs = TradeLogger.get_open_positions()\n    portfolio_display = []\n    total_unrealized_pnl = 0.0\n    \n    if logs:\n        for pos in logs:\n            # Use .get() to handle any modified keys (like 'list', 'current', 'current_price')\n            sym = pos.get('symbol', 'UNKNOWN')\n            chain = pos.get('chain', 'solana') \n            mint = pos.get('mint', '')\n            entry = pos.get('entry', 0.0)\n            amt_tokens = pos.get('amount_tokens', 0.0)\n            \n            # Fetch Price\n            hist = DataService.get_token_history(mint, limit=50)\n            if len(hist) == 0: continue\n            curr = hist[-1]\n            \n            # PnL Logic\n            buy_fee = FeeCalculator.estimate_buy_fees(chain, 0)\n            cost_basis = (entry * amt_tokens) + buy_fee\n            sell_fee = FeeCalculator.estimate_sell_fees(chain)\n            exit_value = (curr * amt_tokens) - sell_fee\n            \n            net_pnl = exit_value - cost_basis\n            net_pnl_pct = (net_pnl / cost_basis) * 100\n            \n            action = \"HOLD\"\n            \n            if net_pnl_pct <= -5.0:\n                action = \"SELL ğŸ›‘ (Stop Loss)\"\n                TradeLogger.log_trade(sym, mint, curr, amt_tokens, action=\"SELL\")\n                if chain == \"solana\":\n                    paper_wallet.balances[\"SOL\"] += exit_value\n                else:\n                    paper_wallet.balances[\"ETH\"] += exit_value\n            elif net_pnl_pct >= 10.0:\n                action = \"SELL ğŸ’° (Take Profit)\"\n                TradeLogger.log_trade(sym, mint, curr, amt_tokens, action=\"SELL\")\n                if chain == \"solana\":\n                    paper_wallet.balances[\"SOL\"] += exit_value\n                else:\n                    paper_wallet.balances[\"ETH\"] += exit_value\n            else:\n                total_unrealized_pnl += net_pnl\n                icon = \"ğŸ“ˆ\" if net_pnl > 0 else \"ğŸ“‰\"\n                \n                portfolio_display.append({\n                    \"icon\": icon,\n                    \"sym\": sym,\n                    \"entry\": entry,\n                    \"curr\": curr,\n                    \"pnl\": net_pnl_pct\n                })\n\n    # --- PRINT THE TABLE (ROBUST VERSION) ---\n    print(\"ğŸ“Š --- OPEN POSITIONS & PnL ---\")\n    if portfolio_display:\n        for item in portfolio_display:\n            # Use .get() to avoid KeyError if keys like 'list' or 'current' are missing\n            sym = item.get('sym', 'UNKNOWN')\n            entry = item.get('entry', 0.0)\n            # Try to get 'curr' or 'current_price' or fall back to 'curr'\n            curr = item.get('curr', item.get('current', item.get('price', 0.0)))\n            pnl = item.get('pnl', 0.0)\n            \n            print(f\"{item.get('icon', '?')} {sym}: Entry ${entry:.6f} -> Now ${curr:.6f} | PnL: {pnl:.2f}%\")\n    else:\n        print(\"   ğŸ“­ No open positions.\")\n    print(f\"------------------------------\\n   Total Unrealized Pnl: ${total_unrealized_pnl:.4f} USD\\n\")\n\n    # 4. SECTOR ROTATION (DEBRIDGE INTELLIGENCE)\n    print(\"\\nğŸŒ‰ [2] DEBRIDGE INTELLIGENCE: TRACKING WHALES (>$2k THRESHOLD)...\")\n    \n    scan_order = [\"solana\", \"base\"]\n    \n    if debridge_service:\n        flow_direction, active_wallets = debridge_service.detect_rotation_signals()\n        \n        print(f\"   Flow Direction: {flow_direction}\")\n        print(f\"   Active Wallets Monitored: {len(active_wallets)}\")\n        \n        if flow_direction == \"SOLANA_TO_BASE ğŸŒŠ\":\n            print(\"   ğŸ’¡ STRATEGY: Capital rotating OUT of Saturn -> BASE.\")\n            scan_order = [\"base\", \"solana\"]\n        elif flow_direction == \"BASE_TO_SOLANA ğŸŒŠ\":\n            print(\"   ğŸ’¡ STRATEGY: Capital rotating OUT of BASE -> SATURN.\")\n            scan_order = [\"solana\", \"base\"]\n        else:\n            print(\"   ğŸ’¡ Observation: No significant bridge activity detected.\")\n    else:\n        print(\"   âš ï¸  DeBridge Intelligence not initialized. Scanning normally.\")\n\n    # 5. ANALYZE SNAPSHOT (WITH ROBUST PRINT)\n    print(\"\\nğŸ” [3] ANALYZING SNAPSHOT DATA...\")\n    \n    found_trade = False\n    \n    for chain_key in scan_order:\n        if chain_key not in snapshot: continue\n        if not isinstance(snapshot[chain_key], list): continue\n            \n        print(f\"\\n   --- Analyzing {chain_key.upper()} ---\")\n        tokens = snapshot[chain_key]\n        \n        for token_data in tokens:\n            if found_trade: break \n\n            sym = token_data.get('symbol')\n            mint = token_data.get('address')\n            tvl = token_data.get('liquidity_usd')\n            mcap = token_data.get('market_cap')\n            \n            # --- FILTER: SKIP STABLECOINS ---\n            if sym in [\"USDC\", \"USDT\", \"USDD\", \"DAI\", \"WETH\", \"WSOL\", \"CBETH\", \"ZRO\", \"WBTC\", \"cbBTC\", \"WETH\"]:\n                continue\n\n            hist = DataService.get_token_history(mint, limit=100)\n            if len(hist) == 0: continue\n            price = hist[-1]\n            \n            print(f\"   [{tokens.index(token_data)+1}] {sym} | TVL: ${tvl:,.0f} | MCap: ${mcap:,.0f}...\")\n            \n            if tvl < Config.MIN_TOKEN_TVL_USD:\n                print(f\"       âŒ TVL Low.\")\n                continue\n            \n            # Forecast\n            preds = knf.forecast(hist, steps=3)\n            \n            if len(preds) > 0 and preds[-1] > hist[-1]:\n                print(f\"       âœ… Trend UP.\")\n                \n                # --- SAFETY CHECK (RugCheck) ---\n                safe = True\n                if chain_key == \"solana\":\n                    safety = rugcheck.verify_token(mint)\n                    print(f\"       ğŸ›¡ï¸  {safety['msg'][:50]}...\")\n                    if not safety['safe']: continue\n                else:\n                    print(f\"       ğŸ›¡ï¸  Base Chain (Skip RugCheck).\")\n\n                # --- SOCIAL SENTIMENT CHECK ---\n                sentiment_score = 0.0\n                sentiment_label = \"Neutral\"\n                \n                if social_service:\n                    socials = token_data.get('socials', [])\n                    sentiment_score = social_service.get_token_sentiment(mint, socials)\n                    \n                    if sentiment_score > 0.05: sentiment_label = \"Bullish ğŸ‚\"\n                    elif sentiment_score < -0.05: sentiment_label = \"Bearish ğŸ»\"\n                else:\n                    sentiment_label = \"No Data\"\n\n                print(f\"       ğŸ’¬ Social Sentiment: {sentiment_label} ({sentiment_score:.2f})\")\n                \n                if sentiment_score < -0.5:\n                    print(f\"       âŒ REJECTED: Community sentiment is toxic.\")\n                    continue\n                \n                # --- BRIDGE QUALITY (WORMHOLE) ---\n                if wormhole_service:\n                    try:\n                        if wormhole_service.is_token_supported(sym):\n                            print(f\"       ğŸŒŒ Wormhole: Supported (High Quality Bridge).\")\n                        else:\n                            print(f\"       ğŸŒŒ Wormhole: Not Supported (Lock-in Risk).\")\n                            continue\n                    except Exception as e:\n                        print(f\"       âš ï¸ Wormhole Check Skipped: {e}\")\n                        pass # Don't block trade if bridge check fails\n\n                # --- AI DECISION ---\n                context = f\"{chain_key.upper()} {sym}. TVL ${tvl:.,0f}. MCap ${mcap:,.0f}. Trend UP. Sentiment: {sentiment_label}.\"\n                decision = reasoner.evaluate(sym, context)\n                \n                if \"BUY\" in decision.upper():\n                    investment = 0.1 if chain_key == \"base\" else 10.0\n                    success = paper_wallet.buy(sym, mint, investment, price, chain=chain_key)\n                    \n                    if success:\n                        fee = FeeCalculator.estimate_buy_fees(chain_key, investment)\n                        net_invest = investment - fee\n                        amount_tokens = net_invest / price\n                        \n                        # Logic: Skip if dust\n                        if amount_tokens > 0.001:\n                            TradeLogger.log_trade(sym, mint, price, amount_tokens, action=\"BUY\", chain=chain_key)\n                            \n                            print(f\"       ğŸ¤– AI: BUY\")\n                            print(f\"       ğŸ’° BOUGHT {amount_tokens:.2f} {sym} @ ${price}\")\n                            print(f\"       ğŸ’¸ Fee: {fee:.6f}\")\n                            found_trade = True\n                            break\n                        else:\n                            print(f\"       âš ï¸ SKIPPED: Position too small (Dust).\")\n                            paper_wallet.balances[chain_key] += investment\n            else:\n                print(f\"       âŒ Trend Down.\")\n    \n    paper_wallet.status()\n\n# --- EXECUTE ---\nrun_universal_scanner()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-02-22T08:29:08.179602Z","iopub.execute_input":"2026-02-22T08:29:08.179929Z","iopub.status.idle":"2026-02-22T08:29:37.945390Z","shell.execute_reply.started":"2026-02-22T08:29:08.179901Z","shell.execute_reply":"2026-02-22T08:29:37.944742Z"}},"outputs":[{"name":"stdout","text":"\n============================================================\nğŸš€ MAS v3: MASTER SCANNER (Rotation + Sentiment + Bridge Quality)\n============================================================\n   ğŸ“‚ Loaded 0 active whale wallets from whales_24h.json\n   ğŸŒŒ Fetching Wormhole Supported Tokens...\n   âš ï¸ Error fetching Wormhole list: 'list' object has no attribute 'get'\nğŸ“‚ Market Snapshot Loaded.\n\nğŸ“ˆ [1] CHECKING PORTFOLIO HEALTH...\nğŸ“Š --- OPEN POSITIONS & PnL ---\n   ğŸ“­ No open positions.\n------------------------------\n   Total Unrealized Pnl: $0.0000 USD\n\n\nğŸŒ‰ [2] DEBRIDGE INTELLIGENCE: TRACKING WHALES (>$2k THRESHOLD)...\n   ğŸ‹ Scanning DeBridge for High-Value Transfers (>$2,000 USD)...\n   Flow Direction: NEUTRAL\n   Active Wallets Monitored: 0\n   ğŸ’¡ Observation: No significant bridge activity detected.\n\nğŸ” [3] ANALYZING SNAPSHOT DATA...\n\n   --- Analyzing SOLANA ---\n   [1] TRUMP | TVL: $28,415,487 | MCap: $796,524,648...\n       âŒ Trend Down.\n   [2] 9bit | TVL: $870,547 | MCap: $179,198,573...\n       âŒ Trend Down.\n   [3] PUMP | TVL: $14,510,975 | MCap: $1,228,893,518...\n       âŒ Trend Down.\n   [4] KMNO | TVL: $1,640,891 | MCap: $109,501,858...\n       âŒ Trend Down.\n   [5] XMN | TVL: $308,517 | MCap: $12,813,341...\n       âŒ Trend Down.\n   [6] BIRB | TVL: $1,768,251 | MCap: $47,633,812...\n       âœ… Trend UP.\n       ğŸ›¡ï¸  âŒ BLOCK: Mint Authority Active, Freeze Authority A...\n   [7] CARDS | TVL: $782,256 | MCap: $11,028,840...\n       âœ… Trend UP.\n       ğŸ›¡ï¸  âŒ BLOCK: Mint Authority Active, Freeze Authority A...\n   [8] SKR | TVL: $612,894 | MCap: $109,336,419...\n       âŒ Trend Down.\n   [9] AVICI | TVL: $798,569 | MCap: $13,927,409...\n       âŒ Trend Down.\n   [10] UMBRA | TVL: $1,810,321 | MCap: $10,199,215...\n       âœ… Trend UP.\n       ğŸ›¡ï¸  âŒ BLOCK: Mint Authority Active, Freeze Authority A...\n   [11] URANUS | TVL: $168,282 | MCap: $1,547,800...\n       âŒ Trend Down.\n\n   --- Analyzing BASE ---\n   [2] AERO | TVL: $19,874,351 | MCap: $301,979,172...\n       âŒ Trend Down.\n\nğŸ’° WALLET BALANCES:\n   SOL: 100.0000\n   ETH: 0.900000\n","output_type":"stream"}],"execution_count":47},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"import torch\nimport gc\n\n\n#    \"\"\"\n#    Frees up unused CUDA memory in PyTorch.\n#    \"\"\"\n    # Delete any large objects referencing GPU memory if they are out of scope\n    # (e.g., within a function where local variables are automatically deleted \n    # when the function exits, or manually via del elsewhere).\n    \n    # Run the garbage collector\ngc.collect()\n    \n    # Empty the PyTorch CUDA cache\ntorch.cuda.empty_cache()\n\n# Example Usage within a function (local variables are automatically freed from Python scope)\n#def my_gpu_task():\n    # Allocate some tensors on the GPU\n#    tensor_a = torch.randn(1024, 1024, device='cuda')\n#    tensor_b = torch.randn(1024, 1024, device='cuda')\n    # ... do something with tensors ...\n    \n    # When the function ends, tensor_a and tensor_b are automatically deleted.\n\n\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-02-22T08:24:33.770718Z","iopub.execute_input":"2026-02-22T08:24:33.771377Z","iopub.status.idle":"2026-02-22T08:24:34.840243Z","shell.execute_reply.started":"2026-02-22T08:24:33.771347Z","shell.execute_reply":"2026-02-22T08:24:34.839212Z"}},"outputs":[],"execution_count":39},{"cell_type":"code","source":"# --- CLEANUP CELL ---\nimport json\nimport os\n\n# 1. Clear the trade log\nif os.path.exists(\"trade_log.json\"):\n    os.remove(\"trade_log.json\")\n    print(\"ğŸ—‘ï¸  Cleared old trade_log.json\")\n\n# 2. Reset Wallet to 100 SOL\nif os.path.exists(\"wallet_state.json\"):\n    os.remove(\"wallet_state.json\")\n    print(\"ğŸ—‘ï¸  Cleared old wallet_state.json\")\n\nprint(\"âœ… Ledger Reset. Run Cell 6 (Wallet) and Cell 7 (Scanner) to start fresh.\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-02-22T08:25:53.231892Z","iopub.execute_input":"2026-02-22T08:25:53.232530Z","iopub.status.idle":"2026-02-22T08:25:53.237561Z","shell.execute_reply.started":"2026-02-22T08:25:53.232501Z","shell.execute_reply":"2026-02-22T08:25:53.237021Z"}},"outputs":[{"name":"stdout","text":"ğŸ—‘ï¸  Cleared old trade_log.json\nğŸ—‘ï¸  Cleared old wallet_state.json\nâœ… Ledger Reset. Run Cell 6 (Wallet) and Cell 7 (Scanner) to start fresh.\n","output_type":"stream"}],"execution_count":40},{"cell_type":"code","source":"# --- RESET CELL ---\nimport os\n\nprint(\"ğŸ§¹ Cleaning up corrupted wallet state...\")\n\n# 1. Delete the corrupt wallet state\nif os.path.exists(\"wallet_state.json\"):\n    os.remove(\"wallet_state.json\")\n    print(\"   âœ… Deleted corrupt wallet_state.json\")\n\n# 2. (Optional) Clear the trade log to start fresh portfolio\nif os.path.exists(\"trade_log.json\"):\n    os.remove(\"trade_log.json\")\n    print(\"   âœ… Deleted old trade_log.json\")\n\nprint(\"\\nğŸ†• System Reset Complete.\")\nprint(\"   Run 'Cell 6' (Wallet) and then 'Cell 7' (Scanner) to start fresh.\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-02-22T08:26:08.960160Z","iopub.execute_input":"2026-02-22T08:26:08.961084Z","iopub.status.idle":"2026-02-22T08:26:08.966758Z","shell.execute_reply.started":"2026-02-22T08:26:08.961050Z","shell.execute_reply":"2026-02-22T08:26:08.965951Z"}},"outputs":[{"name":"stdout","text":"ğŸ§¹ Cleaning up corrupted wallet state...\n\nğŸ†• System Reset Complete.\n   Run 'Cell 6' (Wallet) and then 'Cell 7' (Scanner) to start fresh.\n","output_type":"stream"}],"execution_count":41},{"cell_type":"code","source":"import requests\nimport json\nfrom collections import Counter\nfrom datetime import datetime, timedelta\n\n# Correct Stats API for bulk history filtering\nAPI_URL = \"https://stats-api.dln.trade/api/Orders/filteredList\"\nWHALE_MIN_USD = 100 \nWATCHED_ASSETS = [\"USDC\", \"USDT\", \"ETH\", \"WETH\", \"BTC\", \"WBTC\", \"SOLBTC\"]\nOUTPUT_FILE = \"whales_24h.json\"\n\ndef fetch_24h_whales():\n    # Last 24 hours threshold\n    day_ago_ts = int((datetime.now() - timedelta(hours=96)).timestamp())\n    \n    # Payload as defined in deBridge Integration Guidelines\n    payload = {\n        \"orderStates\": [\"Fulfilled\", \"SentUnlock\", \"ClaimedUnlock\"],\n        \"externalCallStates\": [\"NoExtCall\"],\n        \"skip\": 0,\n        \"take\": 100\n    }\n    \n    try:\n        # Use POST for filteredList as per docs\n        response = requests.post(API_URL, json=payload)\n        \n        # Check if response is valid before parsing\n        if response.status_code != 200:\n            print(f\"Error: Received status {response.status_code}. Possible API change.\")\n            return\n\n        data = response.json()\n        orders = data.get('items', [])\n        \n        whale_log = []\n        wallet_volumes = Counter()\n\n        for order in orders:\n            order_ts = order.get('creationTimestamp', 0)\n            usd_val = order.get('approximateUsdValue', 0)\n            maker = order.get('maker')\n            src_asset = order.get('giveAsset', {}).get('symbol', '').upper()\n\n            # Filter logic for KNF model input\n            if order_ts >= day_ago_ts and usd_val >= WHALE_MIN_USD:\n                if any(asset in src_asset for asset in WATCHED_ASSETS):\n                    whale_log.append({\n                        \"wallet\": maker,\n                        \"usd_value\": usd_val,\n                        \"asset\": src_asset,\n                        \"timestamp\": order_ts,\n                        \"tx_hash\": order.get('creationTxHash')\n                    })\n                    wallet_volumes[maker] += usd_val\n\n        # Save for Kaggle KNF training\n        with open(OUTPUT_FILE, \"w\") as f:\n            json.dump(whale_log, f, indent=4)\n            \n        print(f\"âœ… Processed {len(orders)} orders. Found {len(whale_log)} whales in last 24h.\")\n        print(\"\\nğŸ† --- TOP 10 WHALES (TOTAL 24H VOLUME) --- ğŸ†\")\n        for i, (wallet, vol) in enumerate(wallet_volumes.most_common(10), 1):\n            print(f\"{i:<2} {wallet:<45} ${vol:,.2f}\")\n\n    except Exception as e:\n        print(f\"Critical Script Error: {e}\")\n\nif __name__ == \"__main__\":\n    fetch_24h_whales()\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-02-22T07:56:58.744304Z","iopub.execute_input":"2026-02-22T07:56:58.745183Z","iopub.status.idle":"2026-02-22T07:57:06.566270Z","shell.execute_reply.started":"2026-02-22T07:56:58.745138Z","shell.execute_reply":"2026-02-22T07:57:06.565684Z"}},"outputs":[{"name":"stdout","text":"âœ… Processed 0 orders. Found 0 whales in last 24h.\n\nğŸ† --- TOP 10 WHALES (TOTAL 24H VOLUME) --- ğŸ†\n","output_type":"stream"}],"execution_count":25}]}
